{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toward DNN Deployment Cost Measurement.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7kfe__74jDfo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e28a0651bdc14d3788dc17b853ae83ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11df1b3d196b4e81a950ce983e2007d5",
              "IPY_MODEL_9221fa851e664b4d8315ddb7a35fa73a",
              "IPY_MODEL_b5afd225146b469eb721eaafa6b70c2a"
            ],
            "layout": "IPY_MODEL_de0cc2be3b2b468fbfd75d35f017ccf1"
          }
        },
        "11df1b3d196b4e81a950ce983e2007d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e192f4bb98904b89810e40f78785119d",
            "placeholder": "​",
            "style": "IPY_MODEL_ee274a55fef34b27a2b8df48edb07c03",
            "value": "100%"
          }
        },
        "9221fa851e664b4d8315ddb7a35fa73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d1797ae37c499c87f721c968887e65",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e643ecf682854e2c8426433d0d322443",
            "value": 102530333
          }
        },
        "b5afd225146b469eb721eaafa6b70c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cdfa262b1a451e8ba8d8cf9c1fe84f",
            "placeholder": "​",
            "style": "IPY_MODEL_88f8e54f5f694773a58926658a2b87ee",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 182MB/s]"
          }
        },
        "de0cc2be3b2b468fbfd75d35f017ccf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e192f4bb98904b89810e40f78785119d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee274a55fef34b27a2b8df48edb07c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d1797ae37c499c87f721c968887e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e643ecf682854e2c8426433d0d322443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49cdfa262b1a451e8ba8d8cf9c1fe84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f8e54f5f694773a58926658a2b87ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<h1>Toward DNN Deployment Cost Measurements</h1>\n",
        "Lanxiang Hu\n",
        "</div>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "slVk7mZc0YTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "[1] Ma, Ningning, et al. **Shufflenet v2: Practical guidelines for efficient cnn architecture design**. Proceedings of the European conference on computer vision (ECCV). 2018. [[paper]](https://arxiv.org/abs/1807.11164v1).\n",
        "\n",
        "[2] **THOP: PyTorch-OpCounter**. [[code]](https://github.com/Lyken17/pytorch-OpCounter).\n",
        "\n",
        "[3] **Flops counter for convolutional networks in pytorch framework**. [[code]](https://github.com/sovrasov/flops-counter.pytorch).\n",
        "\n",
        "[4] Chang, Jiho, et al. **Reducing MAC operation in convolutional neural network with sign prediction.** 2018 International Conference on Information and Communication Technology Convergence (ICTC). IEEE, 2018. [[paper]](https://junheecho.com/assets/papers/ictc18.pdf).\n",
        "\n",
        "[5] Model optimization: **model FLOPs**. [[slides]](https://indico.cern.ch/event/917049/contributions/3856417/attachments/2034165/3405345/Quantized_CNN_LLP.pdf).\n",
        "\n",
        "[6] Wang, Xin, et al. **Skipnet: Learning dynamic routing in convolutional networks.** Proceedings of the European Conference on Computer Vision (ECCV). 2018. [[paper]](https://arxiv.org/abs/1711.09485)[[code]](https://github.com/ucbdrive/skipnet).\n",
        "\n",
        "[7] ICLR‘20 Once-for-All tutorial: **Train One Network and Specialize it for Efficient Deployment**. [[paper]](https://arxiv.org/pdf/1908.09791.pdf), [[code]](https://github.com/mit-han-lab/once-for-all/tree/master/tutorial), [[talk]](https://youtu.be/a_OeT8MXzWI)."
      ],
      "metadata": {
        "id": "Oyd-Upgp2ek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "oFWOmF3r0n5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "kUMl6E4lyC-5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "random_seed = 1\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "print('Successfully imported all packages and configured random seed to %d!'%random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VSW4UvGEoP_",
        "outputId": "ffc13e01-ae9a-469d-d71a-729bb636c14a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported all packages and configured random seed to 1!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "cuda_available = torch.cuda.is_available()\n",
        "if cuda_available:\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    print('Using GPU.')\n",
        "else:\n",
        "    print('Using CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgl4rI5OEa7u",
        "outputId": "aae2e1f2-060d-4a80-a614-e2858fdf7d14"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Evaluator Class"
      ],
      "metadata": {
        "id": "F9Ktv8LP0qKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluator class that can be leveraged to measure the deployement cost of a DNN. The costs are usually quantified with the following metrics:\n",
        "1. Memory cost (in MB).\n",
        "2. FLOPs.\n",
        "3. MAC/MACCs (memory access cost/multiply-and-accumulate cost).\n",
        "\n",
        "For memory cost, notice that the unit used here is MB with $1024^2$B = 1MB. \n",
        "\n",
        "According to [2, 3], FLOPs can be quantified by multiplying the size of the feature map on the basis of the parameters. \n",
        "\n",
        "$$\\text{FLOPs} = \\left[\\left(K_h \\times K_w\\right) \\times c_1 +1\\right]  \\left( h \\times w \\right) c_2 \\\\\n",
        "= h w\\left[  K_h \\times K_w\\times c_1c_2 + c_2\\right] \\\\\n",
        "= \\text{feature map size} \\times  \\text{number of parameters}$$\n",
        "\n",
        "Notice that The input and output to convolutional layers are three-dimensional feature maps or namely tensors of size $h \\times w \\times c$ where $h$ and $w$ are spatial sizes of the feature map.\n",
        "\n",
        "For memory access cost (MAC), It can be quantified with number of multiply-and-accumulate operations (MACCs). [1] proposes a metric that sets a lower bound for MAC as \n",
        "\n",
        "\n",
        "$$\\text{MAC} \\geq 2 \\sqrt{h w B} + \\dfrac{B}{hw}$$\n",
        "\n",
        "It reaches the lower bound when input channels and output channels are equal.\n",
        "\n",
        "For $1\\times 1$ group convolution, MAC can be precisely calculated as\n",
        "\n",
        "$$\\text{MAC} = hw (c_1+c_2) + \\dfrac{c_1 c_2}{g} \\\\\n",
        "= hwc_1 + \\dfrac{Bg}{c_1} + \\dfrac{B}{hw}$$\n",
        "\n",
        "According to [2, 3], for a convolutional layer with kernel size $K$, MAC can be quantified with the number of MACCs as\n",
        "\n",
        "$$\\text{MAC} = \\left(K\\times K\\right) \\times \\left(h \\times w \\right)\\times c_1 \\times c_2 \\\\\n",
        "= \\text{kernel size} \\times \\text{feature map size} \\times \\text{input channel} \\times \\text{output channel}$$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1TiTjgC0W_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CostEvaluator:\n",
        "  def __init__(self, **kwargs):\n",
        "    # hyper-parameters\n",
        "    self.turn_on_log = kwargs.get(\"turn_on_log\", 0)\n",
        "\n",
        "  def memory_size_evaluator(self, nn_model):\n",
        "    param_size = 0\n",
        "    for param in nn_model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in nn_model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    total_size_mb = (param_size + buffer_size) / 1024**2\n",
        "    print('model size: {:.3f}MB'.format(total_size_mb))\n",
        "    return total_size_mb\n",
        "\n",
        "  def flops_evaluator(self, nn_model, in_channels, input_h, input_w):\n",
        "    # summing all layers together\n",
        "    total_flops = 0\n",
        "    h_prev = 0\n",
        "    w_prev = 0\n",
        "    h = input_h\n",
        "    w = input_w\n",
        "    c_prev = in_channels\n",
        "\n",
        "    counter = 0\n",
        "    # unwrap nn model\n",
        "    unwrapped_model = [module for module in nn_model.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "\n",
        "    for module in unwrapped_model:\n",
        "      if (self.turn_on_log):\n",
        "        print('processing layer {}'.format(counter))\n",
        "        print('layer type: {}'.format(type(module)))\n",
        "      # there is a possible change in output size if the module is a convolutional layer or maxpool layer\n",
        "      if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "        if (type(module.kernel_size) == int):\n",
        "          # handle int cases\n",
        "          if (module.kernel_size > 1 and module.stride > 1):\n",
        "            ratio = module.stride\n",
        "            h_prev = h\n",
        "            w_prev = w\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "        else:\n",
        "          # handle tuple cases\n",
        "          if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "            ratio = module.stride[0]\n",
        "            h_prev = h\n",
        "            w_prev = w\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "      elif (type(module) == torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
        "        h_prev = h\n",
        "        w_prev = w\n",
        "        h = 1\n",
        "        w = 1\n",
        "\n",
        "      if (type(module) == torch.nn.Conv2d):\n",
        "        # convolutional layer.\n",
        "        if (self.turn_on_log): print('calculating FLOPs for Conv2d...')\n",
        "        c_prev = module.out_channels\n",
        "        total_flops += ((module.kernel_size[0] * module.kernel_size[1]) * module.in_channels  + 1) * (h * w) * module.out_channels\n",
        "      elif (type(module) == torch.nn.MaxPool2d):\n",
        "        # handle else case with maxpool\n",
        "        if (self.turn_on_log): print('calculating FLOPs for MaxPool2d...')\n",
        "        # number of filters\n",
        "        n_1 = h_prev / module.stride\n",
        "        n_2 = w_prev / module.stride\n",
        "        n_tot = n_1 * n_2\n",
        "        # note that number of channels should be held unchanged\n",
        "        total_flops += (module.kernel_size * module.kernel_size + 1) * (h * w) * c_prev * n_tot\n",
        "      elif (type(module) == torch.nn.ReLU):\n",
        "        # handle else case with ReLU \n",
        "        # Assuming number of flops equal to length of input vector, ReLU takes 1 comparison and 1 multiplication\n",
        "        if (self.turn_on_log): print('calculating FLOPs for ReLU...')\n",
        "        total_flops += 2 * (h * w) * c_prev\n",
        "      elif (type(module) == torch.nn.BatchNorm2d):\n",
        "        # handle else case with BatchNorm\n",
        "        if (self.turn_on_log): print('calculating FLOPs for BatchNorm2d...')\n",
        "        mean_ops = (h * w) * module.num_features + 1\n",
        "        std_ops = 2 * ((h * w) * module.num_features + 1)\n",
        "        normalization_ops = 2 * (h * w) * module.num_features\n",
        "        scale_and_shift_ops = 2 * (h * w) * module.num_features\n",
        "        total_flops += mean_ops + std_ops + normalization_ops + scale_and_shift_ops\n",
        "\n",
        "      counter += 1\n",
        "      if (self.turn_on_log): print('------------------')\n",
        "\n",
        "    total_flops_G = total_flops / 10**9\n",
        "    print('total FLOPs: {:.3f} = {}G'.format(total_flops, total_flops_G))\n",
        "    return total_flops\n",
        "\n",
        "\n",
        "  def mac_evaluator(self, nn_model, input_h, input_w):\n",
        "    # summing all layers together\n",
        "    total_mac = 0\n",
        "    h = input_h\n",
        "    w = input_w\n",
        "\n",
        "    # unwrap the nn model\n",
        "    # the complete ResNet object is specifically excluded\n",
        "    unwrapped_model = [module for module in nn_model.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "\n",
        "    counter = 0\n",
        "    for module in unwrapped_model:\n",
        "      if (self.turn_on_log): print('processing layer {}'.format(counter))\n",
        "      if (self.turn_on_log): print('layer type: {}'.format(type(module)))\n",
        "      if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "        if (type(module.kernel_size) == int):\n",
        "          # handle int case\n",
        "          if (module.kernel_size > 1 and module.stride > 1):\n",
        "            ratio = module.stride\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "        else:\n",
        "          # handle tuple case\n",
        "          if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "            ratio = module.stride[0]\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "      elif (type(module) == torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
        "        h_prev = h\n",
        "        w_prev = w\n",
        "        h = 1\n",
        "        w = 1\n",
        "\n",
        "      if (type(module) == torch.nn.Conv2d):\n",
        "        # MAC operations are dominated by computations carried out in convolutional layer\n",
        "        total_mac += (module.in_channels * module.out_channels) * (h * w) * (module.kernel_size[0] * module.kernel_size[1])\n",
        "      counter += 1\n",
        "      if (self.turn_on_log): print('------------------')\n",
        "    total_mac_G = total_mac / 10**9\n",
        "    print('total MACCs: {:.3f} = {}G'.format(total_mac, total_mac_G))\n",
        "    return total_mac\n",
        "  \n",
        "  def inference_time_evaluator(self, device_flops, device_name, nn_model, in_channels, input_h, input_w):\n",
        "    print('starting inference time analysis...')\n",
        "    total_flop = self.flops_evaluator(nn_model, in_channels, input_h, input_w)\n",
        "    inf_time = total_flop / device_flops\n",
        "    print('total inference time: {:.3f}s with {}'.format(inf_time, device_name))\n",
        "    return total_flop / device_flops\n",
        "\n",
        "  def power_evaluator(self, device_power_spec, device_flops, nn_model, in_channels, input_h, input_w):\n",
        "    print('starting inference power analysis...')\n",
        "    total_flop = self.flops_evaluator(nn_model, in_channels, input_h, input_w)\n",
        "    inf_time = total_flop / device_flops\n",
        "    power = inf_time * device_power_spec\n",
        "    print('total inference power consumption: {:.3f}s'.format(power))\n",
        "    return power"
      ],
      "metadata": {
        "id": "HUslWiply1nl"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50 Deployment Cost Estimation"
      ],
      "metadata": {
        "id": "7kfe__74jDfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)"
      ],
      "metadata": {
        "id": "4lCoycqcblHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "e28a0651bdc14d3788dc17b853ae83ac",
            "11df1b3d196b4e81a950ce983e2007d5",
            "9221fa851e664b4d8315ddb7a35fa73a",
            "b5afd225146b469eb721eaafa6b70c2a",
            "de0cc2be3b2b468fbfd75d35f017ccf1",
            "e192f4bb98904b89810e40f78785119d",
            "ee274a55fef34b27a2b8df48edb07c03",
            "a5d1797ae37c499c87f721c968887e65",
            "e643ecf682854e2c8426433d0d322443",
            "49cdfa262b1a451e8ba8d8cf9c1fe84f",
            "88f8e54f5f694773a58926658a2b87ee"
          ]
        },
        "outputId": "37c529e9-cbcd-40dd-9c55-874afb08f200"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28a0651bdc14d3788dc17b853ae83ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider standard imagenet input\n",
        "summary(resnet_50, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaFDOK98ke_G",
        "outputId": "c865fa1d-18ea-444d-d66b-70929bd3620f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.56\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 384.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_resnet50 = [module for module in resnet_50.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "param_size = 0\n",
        "counter = 0\n",
        "\n",
        "for module in unwrapped_resnet50:\n",
        "  print(type(module))\n",
        "  counter += 1\n",
        "print(counter)\n",
        "\n",
        "counter = 0\n",
        "for param in resnet_50.parameters():\n",
        "  counter += 1\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "Y-2hpe_Cb5e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404c9135-5b97-4f2e-8618-eb5c36b67ad0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "142\n",
            "161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_resnet50 = [module for module in resnet_50.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "for module in unwrapped_resnet50:\n",
        "  if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "    print(module.kernel_size)\n",
        "    if (type(module.kernel_size) == int):\n",
        "      # handle int case\n",
        "      if (module.kernel_size > 1 and module.stride > 1):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    else:\n",
        "      # handle tuple case\n",
        "      if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxTovHP64N74",
        "outputId": "0286e140-60b0-46c7-ddb6-e7ebfa161266"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 7)\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "2\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "r88TDRCjwR_t"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_mem = evaluator.memory_size_evaluator(resnet_50)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "resnet50_flops = evaluator.flops_evaluator(resnet_50, 3, 224, 224)\n",
        "resnet50_mac = evaluator.mac_evaluator(resnet_50, 224, 224)\n",
        "resnet50_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', resnet_50, 3, 224, 224)\n",
        "resnet50_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', resnet_50, 3, 224, 224)\n",
        "resnet50_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', resnet_50, 3, 224, 224)\n",
        "resnet50_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', resnet_50, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1F5nM_M_O4p",
        "outputId": "4b46697d-2506-4d7f-d0bf-aa5b670d3775"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 97.695MB\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total MACCs: 4087136256.000 = 4.087136256G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.218s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.008s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.001s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.001s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamically Gated ResNet_50 (SkipNet) Cost Estimation"
      ],
      "metadata": {
        "id": "c3e5tv2q9uyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ucbdrive/skipnet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDALKNKH961h",
        "outputId": "c960dee2-5a48-49b6-ae74-8404aff72895"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'skipnet'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Total 261 (delta 0), reused 0 (delta 0), pack-reused 261\u001b[K\n",
            "Receiving objects: 100% (261/261), 1.69 MiB | 17.61 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'http://people.eecs.berkeley.edu/~xinw/skipnet/resnet-50-rnn-sp-imagenet.pth.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS9wkpReBh_L",
        "outputId": "7c434a37-95ce-4dc9-d920-cbde7d8ea90e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Binary output can mess up your terminal. Use \"--output -\" to tell \n",
            "Warning: curl to output it to your terminal anyway, or consider \"--output \n",
            "Warning: <FILE>\" to save to a file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"http://people.eecs.berkeley.edu/~xinw/skipnet/resnet-50-rnn-sp-imagenet.pth.tar\" \\\n",
        "  -o resnet-50-rnn-sp-imagenet.pth.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxQa1LD5KAqx",
        "outputId": "5b6f433c-eced-4762-f1a1-837f1607d0f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 98.3M  100 98.3M    0     0  71.5M      0  0:00:01  0:00:01 --:--:-- 71.5M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skipnet.imagenet import models"
      ],
      "metadata": {
        "id": "nfL5E6KRG4hT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pkgutil import iter_modules\n",
        "\n",
        "def list_submodules(module):\n",
        "    for submodule in iter_modules(module.__path__):\n",
        "        print(submodule.name)\n",
        "\n",
        "list_submodules(skipnet.imagenet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MItyQD4kLQLN",
        "outputId": "2bd7e960-9356-437d-9021-de645c3f15b0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models\n",
            "train_base\n",
            "train_rl\n",
            "train_sp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_gate_50 = models.imagenet_rnn_gate_50(pretrained=True)"
      ],
      "metadata": {
        "id": "I7HwsNyKL8CD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_rnn_gate_50 = [module for module in rnn_gate_50.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "for module in unwrapped_rnn_gate_50:\n",
        "  if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "    print(module.kernel_size)\n",
        "    if (type(module.kernel_size) == int):\n",
        "      # handle int case\n",
        "      if (module.kernel_size > 1 and module.stride > 1):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    else:\n",
        "      # handle tuple case\n",
        "      if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUgBOGvKFl3C",
        "outputId": "f27ed61c-2e1c-441c-9d16-c8b5533f9626"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 7)\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "2\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "9FfqHta6Qe-9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_gate_50_mem = evaluator.memory_size_evaluator(rnn_gate_50)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "rnn_gate_50_flops = evaluator.flops_evaluator(rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_mac = evaluator.mac_evaluator(rnn_gate_50, 224, 224)\n",
        "rnn_gate_50_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', rnn_gate_50, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RniFEarFsvx",
        "outputId": "bc92222e-a3ac-45c3-d52d-708b6811b05e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 98.276MB\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total MACCs: 5067174378.000 = 5.067174378G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.239s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.009s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.001s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.001s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFA Cost Estimation (MobileNetV3 as the backbone NN)"
      ],
      "metadata": {
        "id": "ErQ7P6c6SbfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Model"
      ],
      "metadata": {
        "id": "vonVn1_0aJya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Installing thop (FLOPs counter) ...')\n",
        "! pip install thop 1>/dev/null\n",
        "# ofa is a package containing training code, pretrained specialized models and inference code for the once-for-all networks.\n",
        "print('Installing OFA...')\n",
        "! pip install ofa 1>/dev/null\n",
        "# tqdm is a package for displaying a progress bar.\n",
        "print('Installing tqdm (progress bar) ...')\n",
        "! pip install tqdm 1>/dev/null\n",
        "print('Installing matplotlib...')\n",
        "! pip install matplotlib 1>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_y6F4cVSu1",
        "outputId": "4e3a2edc-3dc7-4dfe-9f40-27a69fb234ca"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing thop (FLOPs counter) ...\n",
            "Installing OFA...\n",
            "Installing tqdm (progress bar) ...\n",
            "Installing matplotlib...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.utils import download_url"
      ],
      "metadata": {
        "id": "z-epRADOXqXp"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ofa.tutorial import AccuracyPredictor, FLOPsTable, LatencyTable, EvolutionFinder\n",
        "from ofa.tutorial import evaluate_ofa_subnet, evaluate_ofa_specialized"
      ],
      "metadata": {
        "id": "VRqIi3R-X4U1"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ofa_network = ofa_net('ofa_mbv3_d234_e346_k357_w1.2', pretrained=True)\n",
        "print('The OFA Network is ready.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dylqnYS2YUVZ",
        "outputId": "658cc24b-0ecb-4983-b924-7652e2f21332"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/ofa_nets/ofa_mbv3_d234_e346_k357_w1.2\" to .torch/ofa_nets/ofa_mbv3_d234_e346_k357_w1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The OFA Network is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_ofa_network = [module for module in ofa_network.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "for module in unwrapped_ofa_network:\n",
        "  if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "    print(module.kernel_size)\n",
        "    if (type(module.kernel_size) == int):\n",
        "      # handle int case\n",
        "      if (module.kernel_size > 1 and module.stride > 1):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    else:\n",
        "      # handle tuple case\n",
        "      if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcLEaC4YfJX",
        "outputId": "9edb13ba-541a-4f18-e008-6ae08a3c5e12"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n",
            "Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), groups=144, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(192, 192, kernel_size=(7, 7), stride=(2, 2), groups=192, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(288, 288, kernel_size=(7, 7), stride=(2, 2), groups=288, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(816, 816, kernel_size=(7, 7), stride=(2, 2), groups=816, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "VNxan7sDZ4wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ofa_network_mem = evaluator.memory_size_evaluator(ofa_network)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "ofa_network_flops = evaluator.flops_evaluator(ofa_network, 3, 224, 224)\n",
        "ofa_network_mac = evaluator.mac_evaluator(ofa_network, 224, 224)\n",
        "ofa_network_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', ofa_network, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGe0PlweYven",
        "outputId": "0ba4c01c-677f-431a-ce16-0b4137e34e45"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 41.072MB\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total MACCs: 76273854720.000 = 76.27385472G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 1.592s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.057s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.006s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.008s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subnet for SamSung Note10"
      ],
      "metadata": {
        "id": "zufkCVfDaNCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageNet Dataset:"
      ],
      "metadata": {
        "id": "UL6JdG9Ga9ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cuda_available:\n",
        "    # path to the ImageNet dataset\n",
        "    print(\"Please input the path to the ImageNet dataset.\\n\")\n",
        "    imagenet_data_path = input()\n",
        "\n",
        "    # if 'imagenet_data_path' is empty, download a subset of ImageNet containing 2000 images (~250M) for test\n",
        "    if not os.path.isdir(imagenet_data_path):\n",
        "        os.makedirs(imagenet_data_path, exist_ok=True)\n",
        "        download_url('https://hanlab.mit.edu/files/OnceForAll/ofa_cvpr_tutorial/imagenet_1k.zip', model_dir='data')\n",
        "        ! cd data && unzip imagenet_1k 1>/dev/null && cd ..\n",
        "        ! cp -r data/imagenet_1k/* $imagenet_data_path\n",
        "        ! rm -rf data\n",
        "        print('%s is empty. Download a subset of ImageNet for test.' % imagenet_data_path)\n",
        "\n",
        "    print('The ImageNet dataset files are ready.')\n",
        "else:\n",
        "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l72wgBboazxu",
        "outputId": "d51211bd-5355-4ab2-858a-a35a5ccc5318"
      },
      "execution_count": 97,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please input the path to the ImageNet dataset.\n",
            "\n",
            "/home/dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/ofa_cvpr_tutorial/imagenet_1k.zip\" to data/imagenet_1k.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/dataset is empty. Download a subset of ImageNet for test.\n",
            "The ImageNet dataset files are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader:"
      ],
      "metadata": {
        "id": "Nx63u4KHbBCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cuda_available:\n",
        "    # The following function build the data transforms for test\n",
        "    def build_val_transform(size):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(int(math.ceil(size / 0.875))),\n",
        "            transforms.CenterCrop(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(\n",
        "            root=os.path.join(imagenet_data_path, 'val'),\n",
        "            transform=build_val_transform(224)\n",
        "        ),\n",
        "        batch_size=250,  # test batch size\n",
        "        shuffle=True,\n",
        "        num_workers=16,  # number of workers for the data loader\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "    print('The ImageNet dataloader is ready.')\n",
        "else:\n",
        "    data_loader = None\n",
        "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNqCyjsua5L8",
        "outputId": "91a35f7c-cfea-4e9b-e423-3dd029edad2b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ImageNet dataloader is ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy predictor\n",
        "accuracy_predictor = AccuracyPredictor(\n",
        "    pretrained=True,\n",
        "    device='cuda:0' if cuda_available else 'cpu'\n",
        ")\n",
        "\n",
        "print('The accuracy predictor is ready!')\n",
        "print(accuracy_predictor.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stb8DHnDaizS",
        "outputId": "96d1d820-48f4-4da8-f1c2-9532b9981d45"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/acc_predictor.pth\" to /root/.torch/acc_predictor.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy predictor is ready!\n",
            "Sequential(\n",
            "  (0): Linear(in_features=128, out_features=400, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=400, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_hardware = 'note10'\n",
        "latency_table = LatencyTable(device=target_hardware)\n",
        "print('The Latency lookup table on %s is ready!' % target_hardware)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrA6mrgraDUD",
        "outputId": "8746abec-fcb5-4a86-aed2-4e908cdf70df"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/160_lookup_table.yaml\" to /root/.hancai/latency_tools/160_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/176_lookup_table.yaml\" to /root/.hancai/latency_tools/176_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/192_lookup_table.yaml\" to /root/.hancai/latency_tools/192_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 192.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/208_lookup_table.yaml\" to /root/.hancai/latency_tools/208_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 208.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/224_lookup_table.yaml\" to /root/.hancai/latency_tools/224_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 224.\n",
            "The Latency lookup table on note10 is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Hyper-parameters for the evolutionary search process\n",
        "    You can modify these hyper-parameters to see how they influence the final ImageNet accuracy of the search sub-net.\n",
        "\"\"\"\n",
        "latency_constraint = 25  # ms, suggested range [15, 33] ms\n",
        "P = 100  # The size of population in each generation\n",
        "N = 500  # How many generations of population to be searched\n",
        "r = 0.25  # The ratio of networks that are used as parents for next generation\n",
        "params = {\n",
        "    'constraint_type': target_hardware, # Let's do latency-constrained search\n",
        "    'efficiency_constraint': latency_constraint,\n",
        "    'mutate_prob': 0.1, # The probability of mutation in evolutionary search\n",
        "    'mutation_ratio': 0.5, # The ratio of networks that are generated through mutation in generation n >= 2.\n",
        "    'efficiency_predictor': latency_table, # To use a predefined efficiency predictor.\n",
        "    'accuracy_predictor': accuracy_predictor, # To use a predefined accuracy_predictor predictor.\n",
        "    'population_size': P,\n",
        "    'max_time_budget': N,\n",
        "    'parent_ratio': r,\n",
        "}\n",
        "\n",
        "# build the evolution finder\n",
        "finder = EvolutionFinder(**params)\n",
        "\n",
        "# start searching\n",
        "result_lis = []\n",
        "st = time.time()\n",
        "best_valids, best_info = finder.run_evolution_search()\n",
        "result_lis.append(best_info)\n",
        "ed = time.time()\n",
        "print('Found best architecture on %s with latency <= %.2f ms in %.2f seconds! '\n",
        "      'It achieves %.2f%s predicted accuracy with %.2f ms latency on %s.' %\n",
        "      (target_hardware, latency_constraint, ed-st, best_info[0] * 100, '%', best_info[-1], target_hardware))\n",
        "\n",
        "# visualize the architecture of the searched sub-net\n",
        "_, net_config, latency = best_info\n",
        "ofa_network.set_active_subnet(ks=net_config['ks'], d=net_config['d'], e=net_config['e'])\n",
        "print('Architecture of the searched sub-net:')\n",
        "print(ofa_network.module_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP68svPkacXB",
        "outputId": "2acbae8e-26b0-442e-979f-07048d8bda35"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Searching with note10 constraint (25): 100%|██████████| 500/500 [00:21<00:00, 23.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found best architecture on note10 with latency <= 25.00 ms in 21.41 seconds! It achieves 81.44% predicted accuracy with 24.89 ms latency on note10.\n",
            "Architecture of the searched sub-net:\n",
            "3x3_Conv_O24_H_SWISH_BN\n",
            "(3x3_MBConv1_RELU_O24_BN, Identity)\n",
            "((O32, E3.0, K5), None)\n",
            "((O32, E4.0, K3), Identity)\n",
            "(SE(O48, E4.0, K7), None)\n",
            "(SE(O48, E4.0, K5), Identity)\n",
            "((O96, E4.0, K7), None)\n",
            "((O96, E3.0, K7), Identity)\n",
            "((O96, E4.0, K3), Identity)\n",
            "(SE(O136, E6.0, K3), None)\n",
            "(SE(O136, E3.0, K5), Identity)\n",
            "(SE(O136, E3.0, K5), Identity)\n",
            "(SE(O136, E3.0, K3), Identity)\n",
            "(SE(O192, E6.0, K7), None)\n",
            "(SE(O192, E6.0, K3), Identity)\n",
            "(SE(O192, E4.0, K3), Identity)\n",
            "(SE(O192, E3.0, K5), Identity)\n",
            "1x1_Conv_O1152_H_SWISH_BN\n",
            "1x1_Conv_O1536_H_SWISH\n",
            "1536x1000_Linear\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the searched model on ImageNet\n",
        "if cuda_available:\n",
        "    top1s = []\n",
        "    latency_list = []\n",
        "    for result in result_lis:\n",
        "        _, net_config, latency = result\n",
        "        print('Evaluating the sub-network with latency = %.1f ms on %s' % (latency, target_hardware))\n",
        "        top1 = evaluate_ofa_subnet(\n",
        "            ofa_network,\n",
        "            imagenet_data_path,\n",
        "            net_config,\n",
        "            data_loader,\n",
        "            batch_size=250,\n",
        "            device='cuda:0' if cuda_available else 'cpu')\n",
        "        top1s.append(top1)\n",
        "        latency_list.append(latency)\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.plot(latency_list, top1s, 'x-', marker='*', color='darkred',  linewidth=2, markersize=8, label='OFA')\n",
        "    plt.plot([26, 45], [74.6, 76.7], '--', marker='+', linewidth=2, markersize=8, label='ProxylessNAS')\n",
        "    plt.plot([15.3, 22, 31], [73.3, 75.2, 76.6], '--', marker='>', linewidth=2, markersize=8, label='MobileNetV3')\n",
        "    plt.xlabel('%s Latency (ms)' % target_hardware, size=12)\n",
        "    plt.ylabel('ImageNet Top-1 Accuracy (%)', size=12)\n",
        "    plt.legend(['OFA', 'ProxylessNAS', 'MobileNetV3'], loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('Successfully draw the tradeoff curve!')\n",
        "else:\n",
        "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "FNh_ehV1aguw",
        "outputId": "6a597a08-f5b6-45d3-c4ec-5f5c1010b6e9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the sub-network with latency = 24.9 ms on note10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Validate: 100%|██████████| 4/4 [00:09<00:00,  2.40s/it, loss=0.926, top1=78.8, top5=94.6, img_size=192]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: loss=0.92643,\t top1=78.8,\t top5=94.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAELCAYAAAAV7glwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3hVVdaH35VGgECQYpCOdEIJRAELQmAoIoKKBcSKo6IzthErooJimREZHR1RP1FkNKAg0iygJCoqIE16i4KEXhMSCGnr++OcxJt+ktzckuz3ec6Tc/c+Z58fh9yVXdZeS1QVg8FgKA8B3hZgMBj8H2NIDAZDuTGGxGAwlBtjSAwGQ7kxhsRgMJQbY0gMBkO58YghEZF2IrLe5UgWkQdFpKuI/CwiG0VkoYjU9oQeg8HgXsTTfiQiEgjsA3oCc4BxqvqdiIwBWqrqhOLur1+/vrZo0aLI+tTUVGrWrOlGxWXD6CiIr2gxOsqmY82aNUdVtUGhlarq0QMYCPxonyfxpzFrCmwp6f7o6Ggtjri4uGLrPYXRURBf0WJ05MWpDmC1FvG99MYcyUgg1j7fDAy3z6+zjYnBYPAzPDq0EZEQYD8QqaqHRKQ98DpQD1gA3K+q9Qq57y7gLoCIiIjoWbNmFfmMlJQUwsLCKkJ+qTA6CuIrWoyOsumIiYlZo6oXFFpZVFelIg6s3seSIuraAqtKasMMbUqHr+hQ9R0tRkde/HFoM4o/hzWIyLn2zwDgKWCah/UYDAY34DFDIiI1gQHAZy7Fo0RkB7ANa8jzvqf0VAXOJiWxa8IEziYleVuKoZLjMUOiqqmqWk9Vk1zKXlPVtvbxuN19MriJXQsWcHL5chIWLvS2FEMlx3i2VmI2TZ8OwEb7p8FQUQR5W4DBvUytVo2s9HQAJMD6O5H43Xe8IgJAYEgID5096zV9hsqJ6ZFUMu49fJghM2fS6OKLCaxWDYDAatVodPHFDJk5k3sPH/ayQkNlxPRIKhnVwsPpeNNNqCrf3HsvABIYSNQ999Dxppu8rM5QWTE9kkrKpunTyTx9GgkJIfP0aTNPYqhQTI+kkhJYrRpdxo4lo1s3gtetIykhwduSDJUYY0gqKdd+9RUA8fHx9P3rX72sxlDZMUMbg8FQbowhMRgM5cYYEoPBUG6MITEYDOXGGBKDwVBujCExGAzlxhgSg8FQboo1JCJSX0T+ISLfishREcmwf34rIuNEpPCI0gaDoUpRpCERkZeAdUA74D2soEQd7J/vAW2AtfZ1BoOhClOcZ2si0FpVC9tzvg74WERCAeM2aTBUcYo0JKr6Rkk3q2oaUOJ1BoOhclOqyVYRqS0iL4rIIhF5XUQaVZQwg8HgP5R21eZNIAUrF00qVspNg8FQxSlp1ebfIuKaOacZ8JKqLgGeB9pXpDiDweAflNQjWQV8JyI32J/nAutE5H/AWmBGRYozGAz+QbGGRFU/BvoBl4rI18DXWLl7FwA3qepDFS/RYDD4OiUGNrLz0NwnItHAdOA7YJK9YmMwGAwlzpE0sldnFgHXY+Xu3Qf8LCLDPCHQYDD4PiXNkXwKpAH/AQR4XVXfBAYD14uISeFmMBhKHNp0APqqaoaIfAesAFDVQ8BNIhJT0QINBoPvU5Ih+RD4RkSWA72BD1wrVTXOyUNEpB0w26XofOBpIB6YBoQCmcC9qrrKSZsGg8F3KNaQqOqDInIh0BL4WFU3l+UhqrodiAIQkUCseZZ5wLvARFX9UkSGAP8E+pblGQaDwXs4WbX5BfjFjc/sDySo6h4RUaC2XR4O7HfjcwwGg4coLozALyJynYiEFFEfIiLXi8jKUj5zJBBrnz8I/EtE9gKvAE+Usi2DweADiKoWXiHSEZiENdRYC2wHTgG1gLZAd2AZ8KyqbnX0MMso7QciVfWQiLwOfKeqc0XkeuAuVf1LIffdBdwFEBERET1r1qwin5GSkkJYWFiR9Z7C6CiIr2gxOsqmIyYmZo2qXlBopaoWewANgZux5i/eAV4GRgPnlnRvIW0NB5a4fE7iT2MmQHJJbURHR2txxMXFFVvvKYyOgviKFqMjL051AKu1iO+lkzmSg8DMEs2VM0bx57AGrN5JH6zVm37ATjc9x2AweBCP5f4VkZpYYRrvdim+E3hNRIKwHN/u8pQeg8HgPjxmSFQ1FaiXr2w5EO0pDQaDoWIw6SgMBkO5cWRIbCcyg8FgKBSnPZIDIvKaiBS+9GMwGKo0Tg3JYCALWCgiW0XkSRFpWoG6DAaDH+HIkKjqWlX9B9AYeAjoCGwSkTgRGWOvyBgMhipKqSZbVTUb2ApsA45gGZbRwF4Rudn98gwGgz/gdLL1HBG52w4nsBbLgNyiqm1VtT8wCCtFhcFgqII49SNJBOKwjMV8zZfGU1V/EZH57hZnMBj8A6eG5Hy1oqIViareVn45BoPBH3E6R3K7HeAoFxHpISKPVoAmg8HgZzg1JA8AW/KVbcGKJ2IwGKo4Tg1JCJCRrywdK9aqwWCo4jg1JGuAe/OVjcVawTEYDFUcp5OtDwFLbV+RBKAVVsCjARUlzGAw+A+ODImqbhaRtsBQoCnwGbBIVVMqUpzBYPAPHMcjsY1G0cFSDQZDlcWRIbEjmN2LFRaxPlZ8VQBU9bKKkWYwGPwFp5OtU7FCJH6PFdFsLnAuVhR5g8FQxXFqSK4BLlfV14BM++dVgMn9azAYHBuSGsBe+/yMiNRQ1W1At4qRZTAY/Amnk61bgQuBVcBq4FkRScbK4WswGKo4Tg3JA0Cmff4P4C2sjHsmfYTBYCjZkNiBnzsDHwGo6k6gQFpNg8FQdSlxjkRVs4BX88cgMRgMhhycTrYuFJErK1SJwWDwW5zOkYQCc0TkZ6zVG82pUNVbKkKYwWDwH5wakk32YTAYDAVwumlvYnkeIiLtgNkuRecDTwMXAe3ssjrASVWNKs+zDAaD53G616ZfUXWqWqKbvKpuB6LstgKx/E/mqeq/XZ4xBUhyosdgMPgWToc27+X73AAraloiVu+iNPQHElR1T06BiAhwPVCkwTIYDL6L06FNS9fPdq/iKeBUGZ45EojNV9YbOGT7qBgMBj9DVLXkqwq70QotkKiqDUtxTwiwH4h0TW8hIm8Bu1R1ShH33YXtRRsRERE9a1bRYVFSUlIICwtzKqnCMDoK4itajI6y6YiJiVmjqhcUWqmqZTqAy4H9pbxnOLAkX1kQcAho4qSN6OhoLY64uLhi6z2F0VEQX9FidOTFqQ5gtRbxvXQ62ZrHdwRrN3AoBQNCl8QoCg5r/gJsU9XEUrZlMBh8BKeTrTfl+5wK7FDVZKcPEpGaWMGi785XVdicicFg8COcGpIVQLaq5ua2EZFgEammDvfgqGoqUK+Q8tscajAYDD6K0702S7FCLLoSDXztXjkGg8EfcWpIOgMr85WtArq6V47BYPBHnBqSJCAiX1kE1lyJwWDwY+btTC93G04NyVzgYxHpJCI1RKQz8CHwSbkVGAwGrzI/IX9a79Lj1JCMx4rbugrLm3UFsB14stwKDAaD1zibmeWWdpy6yKcBfxORv2MlyDpqO6gYDKVn2qXQpAf0eRRqOXaMNrgRVWXy4q3E7zjilvacOqTdAqxX1Q3AEbusK9BFVWe6RYmh6nBwIxzZDus/gqjRxqB4mKlLd/Dat3m3tbV4fHHu+QP92/DQgLalatOpH8lz2GEAXNgLLACMITGUnix7gm/dTGNQPMSK346Rna08NKAtDw1oy8nT6ew/mcaQ139g90tXlKttp4akNpDfizUJKxiRwVB2jEGpcBJPnObFL7axeOMBmtWtwdJ/XEa1oEDq1AihTo0QtzzDqSHZAowg7yrN1VgTsAZD+ckxKGvehyNb4fYvvaunEnAmPYtp3yUw7bsEzmZmExocwIjuTaiI2U2nhuQx4AsRuQFIAFpjBSga4n5JhipJYAhIgN0jeczbavwaVWXxxgO8+MU29p08A8DQLufxxJAONK5TvcD1w1sFl/uZTldtlotIJ+BGoCnWMvADqrq3+DsNhhIICLKOHANSK7/fo6G0pGVkM3nxVg4kpdHhvNo8e2VHep5fYJtbLle3Kf/wxmmPBFX9A3gJQEQCgMtFZIqqXl9uFYYqQe2k7fCrHc8qfw/EGJBycTw1nZCgAMKqBVE9JJBnh0VyNOUsIy9sRmCAVPjzHRsSyF3yvRWrZ1Ids2JjcMq6j4ha/yT8KlCvNbTsYwyIG8jIyuZ/K/YwdekORvVsxhOXdwBgUKRnJ6ud5P49Fyseya1AR+B7oCbQWVV3V6g6g/+TlQlLn4YVb1pu1BfeBYNegMDyj8urOst3HmXiws3sPJwCwK5DKagqVix1z1KsIRGRxVjBiDYAM4BZqrpfRA4Apz2gz+DPnDkBc8ZAwjIICGZ767toN+QFb6vye/44dprnFm9h6RZrmNisbg2euqIDAzpGeMWIQMk9kj5Y/iNfAl+o6v6Kl2SoFBzdCR/fAMcToEZ9uGEmB35Pz82GZigbu4+mMnDq96RnZVMjJJC/92vNHZe2pFpQoFd1lWRIIrD8R24FnhSRX4GPgGDyxnA1GPIhkHoUGnaGkR9DnWbwe7y3Rfk9LerXpHeb+oRXD+axy9sTUTvU25KAEgyJHR7xQ+BDEWkO3IyVFqIuMFNEXlfVLypepsEvyPF0EoH6reHW+VC/LYTU9K4uP2ZD4kmeW7SFZ66MpFPjcACm3RxNcKDTjfuewbEaVd2jqs+rajvgEmAPZtXGkEPGGfjsTlj17p9ljboZI1JGjpw6y6NzfmX4mz/yy+4TvO6yyc7XjAiUcvk3B1X9GfhZRO53sx6DP5K0D2aPhv3rYOcS6HIdVD/H26r8kvTMbD746Xde/3YXKWczCQ4Ubr+kJff1a+1tacVSJkOSg9MI8oZKzN5fLCOScgjqNIdRscaIlJFN+5K4P3Ydvx21Ipj2a38uT13RgfMbeD8bX0mUy5AYqjjrPoJFD1ob7lr0hutmQM2iXbENxdOgVjUOJqdxfv2aTLiyIzHtzvW2JMcYQ2IoGz+/CV/bkTYvvBMGv2iczErJmUzl7e8SuOPSlgQFBhBRO5SP7+xFx/NqExLke/MgxWEMiaFstL8Cfnwd+j4OF9zubTV+RXa2MmdNIs9/f5rk9G3UqBbEzb2aAxDV1D9D/JTZkIhIMPC1qvZzox6DL5O0D2o3spZ3z2kB9681qzKlZM2eE0xcuJkNiUkAdG9Wh6gm/mk8XClPjyQAy/PVUBXYsQTm3gGXPQKX2It1xog45lByGi99uY156/YBEFG7GsNbwBOjLvaaW7s7KWmvzW/FVDsexIlIO2C2S9H5wNOq+m8RuQ/4G5AFLFbVR522a/AAqvDja/DNs4BaS7yqVq/E4JilWw4xb90+QoICuLN3S+7t25pffl5eKYwIlNwjqQuMA34vpC4EWOTkIaq6HTt4tIgEAvuAeSISAwwHuqrqWXunscFXyDgDC+6HjXaEzZin4LJxxog4QFX54/hpmtezem2jejTj96Op3HpRC5rVq+Flde6nJEOyFjijqt/mrxCRakBZfqP6AwmqukdE/gW8lOOPoqqHy9CeoSJI3g+zbrR6IME14Zq3ocOV3lblF+w8dIqJC7ew9o8TLHu4Lw3DQwkMECYM7ehtaRVGSYZkEkXn900HYsrwzJFArH3eFugtIpOBNGCcqv5ShjYN7mbhg5YRyXEyi4j0tiKfJ+l0BlO/2cHMFXvIylZqhwax49ApGob7xsa6ikQ8mTBPREKA/UCkqh4SkU1AHHA/cCHWPMr5+bP4ichdWJsFiYiIiJ41a1aRz0hJSSEszPuegP6uo1raEVolvM/ONmPJCKntVS3uxt06slX5bm8mc3emk5JhddP7Ng3imjYh1AoputPub+8jJiZmjapeUGilqpbqAP5b2ntc7h0OLHH5/BUQ4/I5AWhQXBvR0dFaHHFxccXWewq/05GZobruY9XsbO9rqWDcrePxub9q88cWafPHFun1037SzfuSvKKjrDjVAazWIr6XZXGfu6kM9+Qwij+HNQCfYw+PRKQt1gTu0XK0bygLZ07Ax9fD52Ph+1e8rcYvUJdO8+iezWlatzpv3tidWXf1omMj9/Tg/Imy+JGUacpeRGpihW2826V4OjDdHuKkA7eq6/+QoeI5sgNiR9qRzOpB84u9rcinOZOexdvfJ7DzcApv3tgdgE6Nw4l7uC9BPri931OUxZCUKeimWkGS6uUrS6d8PRxDechxMjubDBGdYZQdycxQAFXli40HeeGLrblJp+7pk5QbbKgqGxEofTqKxsA3ItJYVfdVkCZDRZPfyazDMLh6mvFULYIt+5OZuHAzK38/DpCbdCrHiBgcGhIRaYYVq/Ui4DhQV0R+Bm5S1T0VqM9QEWRlwLZFgELfJy2394Cq/Re1KCYu3MyMn3aTrXBOjWDGDWrnsaRT/oTTHskMYA0wWFVTRSQMeM4u71tB2gwVRVAI3PA/2LcW2pv0zcUREhSAiHD7xc15sH9bwmuYUAmF4dSQRAMDVTUDQFVTROQx4FiFKTO4l8TVsHYGDH3N6n3UamiMSCH8uOso6VnZuUGF/h7TmhHdm9A2opaXlfk2Tg3JCqAH8KNL2QXAz25XZHA/62Nh4QOQdRYaR0P0bd5W5HP8cew0k7/YwtebD3FeeCjfPtyHGiFB1AoNplao6YWUhFNDkgB8YWfe2ws0BYYAH4vIpJyLVPVp90s0lJmsTFrtmg6J863PF/7VStptyCX1bCb/jd/Fuz/8TnqmlXTqpl7NzRxIKXFqSEKBz+zzc4GzwDysROJN7XLj/+FLnDkBc+6gaeK3EBAEQ14xkcxcUFXmr9/Pi19u5VCyFcP8mm6NeXRw+yqxN8bdODIkqmp+A/2JpH3w4TA4tov04NqEjJ4FLS7xtiqfIj0rm1eX7uBQ8lm6NAnnmSsjiW5uot+XFcd+JCLSBsvFvTFWPJFYVd1Z/F0Gr1CzAYRFQFAoa1o+wEXGiABW0qmcoMrVggKZODySI6fOcm33JgSYoUy5cOpHciWWH8kirAx77YDVInKzqi6oQH0Gp6hCZhoEV/9zeTeoGmd/MlEZ0jOzmfHTbl7/dicjopvQ194K40/pHnwdpz2SF4DhqhqXUyAifYE3AGNIvE3GGWtVJvUojP4UAgKhRl1vq/IJ4rYf5rlFW/jtiBVWZ9/JM2TXMtN57sapIWkC/JCvbLldbvAmyfth1mjYv9aKZHZ4CzTs7G1VXue3Iyk8t2gLcduPAORJOhUfH+9dcZUQp4ZkPfAw8LJL2T/scoO3SFxtGZGUg9Zmu1GzTCQzYO/x0wz69/dkZClh1YJ4oH8bbr24hd8lnfInSooin6yqtYF7gQUi8gB/+pGcBkwQT2/h6mTW/FK4/sMqnS5TVXMjsjetW4NBkQ2pERLII4Pa06BWNS+rq/yU1CMRAFXdKiIdsDbtnYcVLnFljsu8wcNs+8IKQgSWk9ngl6p0usy1f5xg4sItPD20Y+4S7msjuxmnMg9SkiHJnZVS1UwKzpMYvEGbgdbR7nK4YIy31XiN/Emn3orfxf/deiGAMSIepiRDUlNE/ijuAlU1kXA8wdGdUL2uNXwJDIIbP6my+WXSMrJ4b/nvvBm3i9PpWYQEBnDnZVbSKYN3KMmQnAVu9oQQQzHsXApzxsB5XeHmedYwpooakU37krj3o7X8cfw0AAM7RvDUFR0rZdIpf6IkQ5Kpqt95RImhIKrw0+uw9BlAofo5VlCiKjwfcl54KCdOp9Pm3DCeuTKSS9vU97YkAw4nWw1eIMfJbIOdMrnvE3DZo1UuklnS6Qxm/LybsX1aERIUQL2wasy6qxdtI2oRXMXjpPoSJRmSu0uoN5SXaZdCkx7Q51Er2BAUdDK7ehp0HOZdnR4mK1uZ9csfTFmyg+Op6dQICeSvvc8HILKRiZXqaxRrSFT1Y08JqbIc3AhHtsP6j6xYIX0etc73r7WczEbGQsNO3lbpUVb+doyJC7ew5UAyAD1a1uXiVmYI48uUJR2Fwd1kpVs/1820jEjXG6HnvXDZuCrlZLbv5Ble+GIrizccAKBReChPXtGBKzqfl+tsZvBNjCHxJXIMyvr/gQRYXquuQ55Kzk+7jrJ4wwGqBQVwT99W3H1ZK6qHBHpblsEBTsMIjFPVArkcReQfqvqq+2VVcXIMypr34chWuP1L7+qpIFSVXYdTaGMHVh7RvQm7j6VyY8/mNK5T3cvqDKXB6bR3UbFYn3KXEIMLgSEQFArRt8O1H3hbTYWw9UAyI99ZwRX/Wc5e2yckIEB4ZFB7Y0T8kJI27fWzTwNFJIa8y8HnA6cqSliVJCDYiiUSNRr6PAa1IrytyO0cT01nypLtxK76Izfp1O9HU2la1ziU+TMlDW3es3+GYiX8zkGBQ8B9Th4iIu2A2S5F52P1cuoAdwJH7PInVfULJ21WCtKS/zwPCILut1RaA5KZlc3SPRncHx9HclomgQHCbRc158G/tKFOjRBvyzOUk5KWf1sCiMiHqnpLWR+iqtuBKLutQKyYr/OA24Gphc2/VAmW2CPDGvXg7h8gvLF39VQgTy/YzMdbrbmfS1vX5+krO5qkU5UIp1HkbxGRYKAX0EhVZ4tITbsutZTP7A8kqOqeKr2kt3+9lfkuMARuW1wpjYhrjJDbL27Bso17mTiiOwM7Rpjl3EqGo8lWEekM7ADe5c/hTh/yDnecMhKIdfn8dxHZICLTRaTq5AM4ryuMeA8GToZzO3hbjVtJPZvJK19v544Zq1G1IlG0iajFC72rMyiyoTEilRDJ+Y8u9iKR5cDbqjpTRE6o6jl2j2SHqjr+UyoiIVhBkSJV9ZCIRABHseZcngPOU9UCATZE5C7gLoCIiIjoWbNmFfmMlJQUwsLCnEqqMKqiDlXl5wNZfLo9nRNnrd+rp3uFcn6dQI9rKQ6jo2w6YmJi1qjqBYVWqmqJB3CCP43OcZfy407ud7l+OLCkiLoWwKaS2oiOjtbiiIuLK7beUxSp4/flqgc3eV+Hm9mw96Re898ftflji7T5Y4t06Os/6Ordx7yipSSMjrw41QGs1iK+l049W3cD0cDqnAIR6QHscnh/DqNwGdaIyHmqesD+eDWwqZTt+RdnTsDcO6y0Ebd/CU0v9LYit/Dsgs3M+Hk3qlA/LIRHB7Xn2miTdKoq4dSQTAAWi8g0IEREngDGYi3dOsIeCg0g747if4pIFNbQZjeVfbfxV0/CqQPWbt/G3b2txm2EVw8mUITbL23Bff3bUDu06sZLqao4XbVZJCKDsQzHd0Bz4BpVXeP0QWqt7tTLV1Z1oq9t/xJ+/djyWL3qv5bjmZ8St/0wZzOyGdzJ2gM0tk8rhkU1olUD74/3Dd7B8aY9VV2HlZbCUFpOH4eFD1rn/SZA/Tbe1VNGfj+aynOLtrBs22Hqh4Vwcet61A4NpnpIoDEiVZySXOSL2mOTg6rqc27UUzn56nEriVXTXtDrHm+rKTWn0jJ4Y9kupv/4e27SqbsuO5/QIP/tVRncS0k9kuL+dF4OnIO1bGsoipN7YesiCKrud0Oa7Gxl7tpEXv5qO0dTzgJwXXQTHhncjnNrhXpZncGXKMlFvsAchogMxTIeRwD/+/Pqaeo0hXt+tCKh1WvlbTWlIkuVt7//jaMpZ+nerA7PXBlJ16Z1vC3L4IM4niOxdwI/D0QAE4H/qWp2RQmrVNRtaR1+wKHkNIIChHph1QgODOC54Z04mHyGq6IaG49UQ5GU6CIvIr1EZBnwITATaK+qHxojUjz1jq6EX/4Psn33NU1duiP3/GxmFv+N30XMK/H886vtueUXtarH1d2aGCNiKJaSJlsXAT2Bf2IlDD9jl+caIGNQCiH1KO22vwmbkqBGfYi8ytuKCuW1b3fy4F/a8M3Wwzy/eAt7jlkBhk6eSScrW03aS4NjShraDLF/vgy8lK9OsBzJ/Gf20FN8MY6QjCRofil08O00ErdMX8UPO48C0ObcMJ6+siO92zTwsiqDv1GSIfGPgb0vsXkebJ5HVkAogcPf8NmEVgeSzgDww86j1A4N4qEBbbmpV3OTdMpQJkpatdnj+tke0kS47I8xuJJyBBY/DEBCq1tp62MTrFOX7uC1b3cWKE9Oy2Tiwi2cPJ3BQwPaekGZwd9xGkW+DvBf4FogA6gpIsOAHqpqAkCDlad38T/g9DFoeRn7Gw3G176SDw1om8dQtHh8MbtfusKLigyVBaf92GlAEtYeGztXAj8DN1SEKL/kbDKc2A0hYTDsDSsvjcFQRXDqR9IfK8RihogogKoeEZFzK06anxEaDncusxzPzmkO/O5tRQaDx3BqSJKA+kDu3IiINHP9XGVRhRwfi8BgvwoP8EB/724ezMjIIDExkbS0NI8+Nzw8nK1bt3r0mf6kIzQ0lCZNmhAc7DwchFND8n/AXBEZDwSIyEXAC1hDnqrNxjmwbSEMmQJh/rVs6u2J1cTERGrVqkWLFi086vB26tQpatXyfgR7X9Shqhw7dozExERatnS+WOB0IP8yVl6aN4FgrKDP84HXSqW4snHqIHwxDrbMh51fe1uN35GWlka9evWM16wPISLUq1ev1L1Ep4GNFMtoVG3D4YoqLHoI0k5Cq/5WdjxDqTFGxPcoy/+J03QU/Yo4LhGR5qV+amVgwyew/QuoVhuG/efPeRJDhXI2KYnPr76as0lJbmkvMTGR4cOH06ZNG1q1asUDDzxAeno68fHxhIeHExUVRVRUFH/5y19y77nqqqvo1auXW55fWXA6tHkP+NI+/udyPgvYJSJrRMQ/w36VheQD8OUj1vngFytlcitfZdeCBez6/HMSFi4sd1uqyjXXXMNVV13Fzp072bFjBykpKYwfPx6A3r17s379etavX88333wDwMmTJ1mzZg1JSUn89ttv5dZQWSiNIXkdqKOqjbBy9v4ba7K1DvALlsNa5UcVFj0IaUnQZqAZ0niYTdOtnGwbp5clN1teli1bRmhoKLfffjsAgYGBTJ06lenTp3P69OlC7/nss8+48sorGTlyJMXlV6pqOF21eQAreVUmgKqeEZGngP2qOllEHgYSK0qkT5GdCXXPh+rnwJWvmSGNm3illPThQH0AABmNSURBVO9xb1yco3vGFZMAbvPmzURHR+cpq127Ns2aNWPXrl388MMPREVFAXDdddcxfvx4YmNjefrpp4mIiGDEiBE8+eSTpdJdWXFqSFKBC7G8WXOIBnLMdtUJJRAYbA1nLnsEatT1thpDBdK7d28WLVqU+/nQoUPs3LmTSy+9FBEhODiYTZs20alTJy+q9A2cGpKngSUisgDYCzTBik9yn13fH5jjfnk+hCpknIaQmtZnY0TcSnE9hxw2z5zJN/feS0ZKCsFhYQx46y063nRTmZ/ZsWNH5szJ+2ubnJzMH3/8QevWrVmyZEmeuk8++YQTJ07k+lckJycTGxvL5MmTy6yhsuBojkRVP8QKcLQNCMdKKH6RXY6qLlJVx8my/JJ1/4M3e8Jv33lbSZVl0/TpZJ4+TWBoKJmnT5d7nqR///6cPn2aDz/8EICsrCwefvhhbrvtNmrUqFHg+tjYWL766it2797N7t27WbNmjZknsXG8s0xVt6jqc6p6j6pOUtUtFSnMp0hKhK+fhKS9kHLI22qqLIHVqtFl7FhGr1hBl7FjCQwJKVd7IsK8efP49NNPadOmDW3btiU0NJQXXnihwLW7d+9mz549eZZ9W7ZsSXh4OCtXriyXjspAaYI/DwP6YO25yZ3lUtVbKkCX76AKC+6zdve2uwI6X+dtRVWWa7/6Kvd8wJtvuqXNpk2bsrCQpeS+ffvSt2/f3M8tWrRg3759Ba5bu3atW3T4O04d0p4B3ravvw44BgwCTlacNB9h7QxIWGat0gydalZpDIZCcDq0GQMMUNWHgHT755VACyc3i0g7EVnvciSLyIMu9Q+LiIpI/dL+AyqUk3vhaztu05BXoFaEd/UYDD6K06FNHVXdZJ+ni0iwqq4SkT5OblbV7UAUgIgEAvuAefbnpsBA4I9SKa9ocoY06aegw5XQaYS3FRkMPovTHkmCiETa55uAe0TkZuBEGZ7ZH0hwiQc7FXgUKyK97yACPe+GcyPhilfNkMZgKAanPZKngHr2+RPAR0AYcG8ZnjkSiAUQkeHAPlX91Sd3gba7HNoONkbEYCgBUQeOQG57mEgIsB+IBE4BccBAVU0Skd3ABap6tJD77gLuAoiIiIgubu0+JSWFsLCwsovUbGqcTuR0zWZlb8MdOtyEr+iAglrCw8Np3bq1x3VkZWURGOj9dEy+rGPXrl0k5dthHRMTs0ZVLyi0EVV1dAA1gC7Axa6H0/vtNoYDS+zzzsBhYLd9ZGLNkzQsro3o6Ggtjri4uGLrS2TlO6rPnqP6w9RyNVNuHW7CV3SoFtSyZcuWMrXz6pLt5dKRnJycex4QEKBdu3bVyMhIvfbaazU1NbVcbRdHnz599JdffilUR2mJi4tTQBcsWJBbdsUVV+R5x0eOHNGgoCB966238tz73nvvaadOnbRz584aGRmpsbGxBdov7P8GWK1FfC+dLv/eAhwElmFFSss5SuvWNwp7WKOqG1X1XFVtoaotsDb9dVfVg6Vs030c/x2WPg2a5TdJv6siheXmKSvVq1dn/fr1bNq0iZCQEKZNyxs9NDMz023PcjdNmjQp1j3/008/pVevXsTGxuaWJSYmMnnyZJYvX86GDRtYsWIFkZGRRbbhFKeTrf8ERqhqfVVt6nI47v+LSE1gAPBZWYRWONnZMP9v1n6aTiOg43BvKzJ4mN69e7Nr1y7i4+Pp3bs3w4YNo2PHjqSlpXH77bfTuXNnunXrRlxcHADDhw/Pda9/++23GT16NAkJCXTv/mcA8J07d+b5nMOSJUvo378/3bt357rrriMlJQWAxx9/nI4dO9KlSxfGjRsHWAahU6dOdO3alcsuuyy3ja5duxIeHs7SpUsL/ffExsYyZcoU9u3bR2KitTn/8OHD1KpVK3eIGRYWRosWLcr55pxPtqYD8eV5kKqm8ueEbWH1LcrTfrn55V3Y8yPUbACX/8urUqoqLR5fXGTdC1d35saezRxdW5akX5mZmXz55ZcMHjwYsDxWN23aRMuWLZkyZQoiwsaNG9m2bRsDBw5kx44dvPPOO1xyySW516xYsYK6desSHh7O+vXriYqK4v3338+Nd5LD0aNHef7551mwYAENGzbk5Zdf5tVXX+Vvf/sb8+bNY9u2bYgIJ09a/p6TJk3i66+/pnHjxrllOYwfP54JEyYwYMCAPOV79+7lwIED9OjRg+uvv57Zs2fz8MMP07VrVyIiImjZsiX9+/fnmmuuyePBW1ac9kgmAK/6nMOYuziWAEufsc6HToWaRdo7g5d4ct5GWjy+uFgDUhbOnDlDVFQUF1xwAc2aNeOOO+4AoEePHrm7fJcvX85N9i7j9u3b07x5c3bs2EFERASTJk0iJiaGKVOmULeutSP8r3/9K++//z5ZWVnMnj2bG2+8Mc8zV6xYwZYtWxg4cCBRUVHMmDGDPXv2EB4eTmhoKHfccQefffZZ7sbBSy65hNtuu413332XrKysPG3l9FCWL1+ep3z27Nlcf/31AIwcOTJ3eBMYGMhXX33FnDlzaNu2LQ899FChe4tKi9MeyQ5gEnCvyzKtYMWF9v60c3n5+knIPGPto+lwpbfVVFmc9iTcmWo0Z44kPzVr1nR0/8aNG6lXrx779+/PLRsxYgQTJ06kX79+REdHU69e3j9MqsqAAQN45513CqSjWLVqFd9++y1z5szhjTfeYNmyZUybNo2VK1eyePFioqOjWbNmTZ57xo8fz/PPP09Q0J9f59jYWA4ePMhHH30EwP79+9m5cydt2rRBROjRowc9evRgwIAB3Hrrrbz44ouO/r1F4bRHMhP4EOgKtLWPNvZP/2foVOg6Ci7/p7eVGHyQ3r17534hd+zYwR9//EG7du1YtWoVX375JevWreOVV17h99+t7IqhoaEMGjSIe+65p8CwBqBXr178+OOPJCQkAJCampobLzYpKYkhQ4YwdepUfv31VwASEhLo2bMnkyZNokGDBuzduzdPewMHDuTEiRNs2LAhV2NKSgr79u3LDXnwxBNPEBsby/79+/NsNFy/fj1NmzYt9ztyakjqAU+r6iZVTXA9yq3AF6jdCK6eZoIVGQrl3nvvJTs7m86dO3PDDTfwwQcfAHDnnXcyffp0GjVqxJQpUxgzZkyOmwOjR48mICCAgQMHFmivQYMGfPDBB4wZM4YuXbpw0UUXsW3bNk6dOsXQoUPp0qULl156Ka+++ioAjzzyCJ07d6ZTp05cfPHFdO3atUCb48ePzzUwsbGxXH311XnqR4wYQWxsLBkZGYwbN4727dsTFRXF7Nmzefnll8v/kopaF9a8/h+vArc4ubaiD7f5kWRlqq6PtX5WAL7iv+ErOlR904+kovjXv/6lTz31lNd1OKEwHaX1I3E6R9ID+LudsjNPZB9VvazwW3ycFW/BkvGwbTHcMNPbagylwNupRkvi6quvJiEhgWXLlnlbisdwakjetY/KwZEdsOw569ykkzC4mXnz5nlbgsdxmrJzRkUL8RjZWTD/XshMs4xIu8HeVmQw+D3FGhIR6VdSA6rqX/23n9+AxF+gViMYVP71c4PBUHKP5L0S6hU4301aKp4j22GZvTdh2OtQvY539RgMlYRiDYmqVq6da6vegayz0O1maDOg5OsNBoMjHKejqBRc/k8r9uogk9DIr5h2KSz6B5xy/8ZwEcl1fwdrz02DBg0YOnRosfc9++yzvPLKKwXK9+/fz7XXXgtAfHx8ie3Ex8cjInki2Q8dOpT4+Phi7/vggw9yvWknTpzIE088kad+/fr1dOjQAYDBgwfTtWtXIiMjGTt2bAE3e3dQtQxJQCD0uBNCw72txFAaDm6EdTPhta5uNyg1a9Zk06ZNnDlzBoClS5fSuHHjMrfXqFGjAtn7SqKkcACF4WpIRo0axezZs/PUz5o1i1GjRgFWhsBff/2VTZs2ceTIET799NNSPcsJld+QZGXCV09CUsGcJAY/IivdWmmrAIMyZMgQFi+2NgPGxsbmfgEBjh8/zlVXXUWXLl3o1atXrhs6wK+//spFF11EmzZtePddyzti9+7dheYCTk1NZcyYMfTo0YNu3boxf/783LriwgGsWbOGPn36EB0dzaBBgzhw4ABz5sxh9erVjB49mqioKJo2bco555yTJ1HXJ598kvvvqF27NmD1ttLT06mIsKaOE2T5LT9OhRVvwu/fw9gfTPxVX+ZZBz3FrHTr5+r3rKPQdpIKLy+CkSNHMmnSJIYOHcqGDRsYM2YMP/zwAwDPPPMM3bp14/PPP2fZsmXccsstuZv8cgIDpaam0q1bN664ouiNhJMnT6Zfv35Mnz6dkydP0qNHD77//vvc+sLCAWRkZHDfffcxf/58GjRowOzZsxk/fjzTp0/njTfe4JVXXuGCC6zIh6NGjWLWrFn07NkzN5xBmzZtctsaNGgQq1at4vLLL88dermTyt0jObQZ4u19BAOfM0bEUChdunRh9+7dxMbGMmTIkDx1y5cv5+abbwagX79+HDt2jOTkZMAKbFS9enXq169PTEwMq1atKvIZS5Ys4aWXXiIqKoq+ffuSlpaWG2wICg8HsH37djZt2sSAAQOIiori+eefz3OPKzfccANz5swhOzs7z7Amh6+//poDBw5w9uzZCvG4rTw9kmmXQpMehARfan3OyoB5YyE7Ay4YA61ivKvPUDJF9SQK66kEhoAEWE6FfR4rd/KyYcOGMW7cOOLj4zl27Jije/IPEYobMqgqc+fOpV27drllp06dyhMSIH84AFUlMjKSn3/+uUQtTZs2pWXLlnz33XfMnTu30HtCQ0MZPnw48+fPLxAIqbxUnh6JPSHXc+Xd1vj5m0lwcAPUaQYDJnlbncFdBIZAUKi1hP/ABhj6qlsyII4ZM4ZnnnmGzp075yl3DSEQHx9P/fr1c+cc5s+fT1paGseOHSM+Pp4LL7ywyPYHDRrEf/7zn9zdwevWrStwTf5wAO3atePIkSO5RiEjI4PNmzcDUKtWLU6dOpXn/lGjRvHQQw9x/vnn06RJE8CK3H/gwAHAmiNZvHgx7du3L93LcUDlMSQAWekEZqfD2g/h59etsgHPQbVaxd9n8H0qyIDk0KRJE+6///4C5c8++yxr1qyhS5cuPP7448yY8edukS5duhATE0OvXr2YMGECjRo1KrL9CRMmkJGRQZcuXYiMjGTChAmFXucaDiAkJIQ5c+bw2GOP0bVrV6Kiovjpp58AuO222xg7dixRUVG5K07XXXcdmzdvzjOsSU1NZdiwYXTp0oWoqCjOPfdcxo4dW/oXVAIezWvjDi644AJdvXp1wYrCur8SYP0CRo2GPo9CrYYVL9AmPj7eLbEwK4sOKKhl69atub4OxWIPW90xhAFrSJE/Mpk38GUdhf3fiEiReW0qzxxJYWi2tWS45n04shVu/9LbigxlYezykq8xeJXKbUjyT8gZDIYKoXIaEjfP6BsMhuKpXIYkMIQshcBuNxsD4ieoaoV4WhrKTlnmTSuPIWnYGZr0YGVwby4edHXJ1xu8TmhoKMeOHaNevXrGmPgIqsqxY8cIDQ0t1X2Vx5DYE3LpJeyaNPgOTZo0ITExkSNHjnj0uWlpaaX+olQlHaGhobl+KE6pPIbE4HcEBwfnZrPzJPHx8XTr1s3jz63MOiqXQ5rBYPAKxpAYDIZyYwyJwWAoN37nIi8iR4A9xVxSHzjqITnFYXQUxFe0GB15caqjuao2KKzC7wxJSYjI6qL2Axgd3sVXtBgd7tdhhjYGg6HcGENiMBjKTWU0JO94W4CN0VEQX9FidOSl3Doq3RyJwWDwPJWxR2IwGDyMXxsSEZkuIodFZJNL2bMisk9E1tvHkOLacJOOpiISJyJbRGSziDxgl9cVkaUistP+eY6XdHj0nYhIqIisEpFfbR0T7fKWIrJSRHaJyGwRCfGSjg9E5HeX9xFVkTpc9ASKyDoRWWR/9uj7KEZH+d+HqvrtAVwGdAc2uZQ9C4zzsI7zgO72eS1gB9AR+CfwuF3+OPCyl3R49J0AAoTZ58HASqAX8Akw0i6fBtzjJR0fANd68nfE1vAP4GNgkf3Zo++jGB3lfh9+3SNR1e+B4z6g44CqrrXPTwFbgcbAcCAnWvAM4Cov6fAoapFifwy2DwX6ATn5LD3xPorS4XFEpAlwBfB/9mfBw++jMB3uwq8NSTH8XUQ22EOfCh1O5EdEWgDdsP76RajqAbvqIOCxSEv5dICH34ndfV4PHAaWAgnASVXNtC9JxANGLr8OVc15H5Pt9zFVRKpVtA7g38CjQLb9uR5eeB+F6MihXO+jMhqSt4BWQBRwAJjiqQeLSBgwF3hQVZNd69TqQ3rkr2EhOjz+TlQ1S1WjgCZAD8D9yVTKoENEOgFP2HouBOoCFRrQV0SGAodVdU2JF3tHR7nfR6UzJKp6yP7lyQbexfolrnBEJBjry/uRqn5mFx8SkfPs+vOw/ip6XIe33on97JNAHHARUEdEcmLgNAE8ltndRcdgewioqnoWeJ+Kfx+XAMNEZDcwC2tI8xqefx8FdIjI/9zxPiqdIcn54tpcDWwq6lo3PlOA94CtqvqqS9UC4Fb7/FZgfv57PaHD0+9ERBqISB37vDowAGu+Jg7IyWDtifdRmI5tLsZdsOYlKvR9qOoTqtpEVVsAI4FlqjoaD7+PInTc5I734dcR0kQkFugL1BeRROAZoK+9fKXAbuBuD0i5BLgZ2GiPxwGeBF4CPhGRO7B2LF/vJR2jPPxOzgNmiEgg1h+rT1R1kYhsAWaJyPPAOiyj5w0dy0SkAdaqznrA/annnPEYnn0fRfFRed+H8Ww1GAzlptINbQwGg+cxhsRgMJQbY0gMBkO5MYbEYDCUG2NIDAZDuTGGxFClEZGOIrLa9qFwZ7tzReRyd7bpyxhD4oeIiIpI61Jc/3f7y3JWRD4opL6/iGwTkdNihSFoXkxbu0XkL2XQHC8ify3tfR7gOeAVdb8fxMvA825u02cxhqRqsB/rl3p6/goRqQ98BkzA2mexGpjtUXVewvbojAE+d3fbqroKqC0iXo8S7wmMIfES9l/2cfaOyyQ7sE2oS/2ddsCb4yKyQEQa2eXf25f8KiIpInKDXT7UDkpzUkR+EpEuOW2p6meq+jlwrBAp1wCbVfVTVU3Dil3SVURKtclORM4RkUUickRETtjnTey6yUBv4A1b8xt2eXuxAj4dF5HtInK9S3sfiMibIrJYRE6JFQColUt9pMu9h0TkSRFpaPeq6rlc193WFFyI7AHAWvvfnXP9bhF5xP5/SRWR90QkQkS+tHV8I/buabECJ/1PRI7Z7/0XEXHd4R2PtWW/0mMMiXe5HhgMtAS6ALcBiEg/4EW7/jws9/pZAKp6mX1vV1UNU9XZItINq7dxN9b29LeBBeJsO3gk8GvOB1VNxdryH1nKf0sA1oav5kAz4Azwht3meOAH4O+25r+LSE2s8AIfA+di7f34r4h0dGlzJDAROAfYBUwGEJFawDfAV0AjoDXwraoexPryum5FuBmYpaoZhWjuDGwvpHwElpFpC1wJfIm11aCB/e+8377uViAcaIr13sfa/+4ctgJdC3tZlQ1jSLzL66q6X1WPAwuxtvkDjAamq+pae0fmE8BFYsUYKYy7gLdVdaW9y3cGcBYrGlhJhAFJ+cqSsCKsOUZVj6nqXFU9bQdVmgz0KeaWocBuVX1fVTNVdR3WruXrXK6Zp6qr7JgdH/Hn+xkKHFTVKaqapqqnXOKMzABuAisWCTAKmFmEhjrAqULK/2PvmN6HZQBXquo6u+cyDyvOC0AGlgFpbb/3NfnCR5yyn1HpMYbEuxx0OT+N9aUG669sblpSO8rXMYoOfNMceNjuXp8UkZNYfyUbOdCQAtTOV1abwr9gRSIiNUTkbRHZIyLJwPdY2+QDi9HcM5/m0UBDl2uKej9NsXpNhTEf6CgiLbF6FUn2fEVhnKBwg3nI5fxMIZ9zdMwEvsbaeLdfRP6ZbwhVCzhZxLMrFcaQ+Cb7sb5oANjDgHoUHa9iLzBZVeu4HDVUNdbBszbj0v22n9XKLi8NDwPtgJ6qWhsrni5YO0qhYFCnvcB3+TSHqeo9Dp61Fzi/sAq71/AJVq/kZorujQBswBq+lAlVzVDViaraEbgYq6d0i8slHXAZNlZmjCHxTWKB20Ukyp7neAGre73brj9E3i/Su8BYEekpFjVF5Ap7LgERCbIncgOBQHuSMCeExDygk4iMsK95GtigqtuK0RdstxHq0lYtrL/WJ0WkLlZIB1fya14EtBWRm0Uk2D4uFJEODt7PIuA8EXlQRKqJSC0R6elS/yHWfNMwijckS4HurpPcpUFEYkSks93rSsYa6riGMOyDNb9S6TGGxAdR1W+wlmPnYoVGbIU18ZjDs1hxNk6KyPWquhq4E2ty8wTWxORtLtc/hfUlfxzrL/UZuwxVPYI1uTjZvrdnvmcVxhd2GznHs1ixQKtjZbVfgTUR6sprwLX2is7r9jzKQPtZ+7GGMS8DJU4Q2/cOwJoIPQjsxFrGzan/EesLvVZV9xTaiHXdIWAZVpDustAQK3hzMtbE6nfYhktELgRSihlWVSpMPBJDpURElgEfq2qx0dLtVaIZQA93OqWJyFzgPVX9wl1t+jLGkBgqHXZvYCnQ1O69GCoYM7QxVCpEZAaWj8mDxoh4DtMjMRgM5cb0SAwGQ7kxhsRgMJQbY0gMBkO5MYbEYDCUG2NIDAZDuTGGxGAwlJv/B1xgmms9Z0tvAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully draw the tradeoff curve!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "-_vgDc98bTCK"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ofa_network_mem = evaluator.memory_size_evaluator(ofa_network)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "ofa_network_flops = evaluator.flops_evaluator(ofa_network, 3, 224, 224)\n",
        "ofa_network_mac = evaluator.mac_evaluator(ofa_network, 224, 224)\n",
        "ofa_network_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', ofa_network, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPAoZ7bibKUp",
        "outputId": "1aea3320-b4af-4d28-a1be-ed6179ceede5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 41.072MB\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total MACCs: 76273854720.000 = 76.27385472G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 1.592s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.057s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.006s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.008s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Us0ZZzvJbTs_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}