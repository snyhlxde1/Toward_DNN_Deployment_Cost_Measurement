{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toward DNN Deployment Cost Measurement.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7kfe__74jDfo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e28a0651bdc14d3788dc17b853ae83ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11df1b3d196b4e81a950ce983e2007d5",
              "IPY_MODEL_9221fa851e664b4d8315ddb7a35fa73a",
              "IPY_MODEL_b5afd225146b469eb721eaafa6b70c2a"
            ],
            "layout": "IPY_MODEL_de0cc2be3b2b468fbfd75d35f017ccf1"
          }
        },
        "11df1b3d196b4e81a950ce983e2007d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e192f4bb98904b89810e40f78785119d",
            "placeholder": "​",
            "style": "IPY_MODEL_ee274a55fef34b27a2b8df48edb07c03",
            "value": "100%"
          }
        },
        "9221fa851e664b4d8315ddb7a35fa73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d1797ae37c499c87f721c968887e65",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e643ecf682854e2c8426433d0d322443",
            "value": 102530333
          }
        },
        "b5afd225146b469eb721eaafa6b70c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cdfa262b1a451e8ba8d8cf9c1fe84f",
            "placeholder": "​",
            "style": "IPY_MODEL_88f8e54f5f694773a58926658a2b87ee",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 182MB/s]"
          }
        },
        "de0cc2be3b2b468fbfd75d35f017ccf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e192f4bb98904b89810e40f78785119d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee274a55fef34b27a2b8df48edb07c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d1797ae37c499c87f721c968887e65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e643ecf682854e2c8426433d0d322443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49cdfa262b1a451e8ba8d8cf9c1fe84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f8e54f5f694773a58926658a2b87ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<h1>Toward DNN Deployment Cost Measurements</h1>\n",
        "Lanxiang Hu\n",
        "</div>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "slVk7mZc0YTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "[1] Ma, Ningning, et al. **Shufflenet v2: Practical guidelines for efficient cnn architecture design**. Proceedings of the European conference on computer vision (ECCV). 2018. [[paper]](https://arxiv.org/abs/1807.11164v1).\n",
        "\n",
        "[2] **THOP: PyTorch-OpCounter**. [[code]](https://github.com/Lyken17/pytorch-OpCounter).\n",
        "\n",
        "[3] **Flops counter for convolutional networks in pytorch framework**. [[code]](https://github.com/sovrasov/flops-counter.pytorch).\n",
        "\n",
        "[4] Chang, Jiho, et al. **Reducing MAC operation in convolutional neural network with sign prediction.** 2018 International Conference on Information and Communication Technology Convergence (ICTC). IEEE, 2018. [[paper]](https://junheecho.com/assets/papers/ictc18.pdf).\n",
        "\n",
        "[5] Model optimization: **model FLOPs**. [[slides]](https://indico.cern.ch/event/917049/contributions/3856417/attachments/2034165/3405345/Quantized_CNN_LLP.pdf).\n",
        "\n",
        "[6] Wang, Xin, et al. **Skipnet: Learning dynamic routing in convolutional networks.** Proceedings of the European Conference on Computer Vision (ECCV). 2018. [[paper]](https://arxiv.org/abs/1711.09485)[[code]](https://github.com/ucbdrive/skipnet).\n",
        "\n",
        "[7] ICLR‘20 Once-for-All tutorial: **Train One Network and Specialize it for Efficient Deployment**. [[paper]](https://arxiv.org/pdf/1908.09791.pdf), [[code]](https://github.com/mit-han-lab/once-for-all/tree/master/tutorial), [[talk]](https://youtu.be/a_OeT8MXzWI)."
      ],
      "metadata": {
        "id": "Oyd-Upgp2ek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "oFWOmF3r0n5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kUMl6E4lyC-5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "random_seed = 1\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "print('Successfully imported all packages and configured random seed to %d!'%random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VSW4UvGEoP_",
        "outputId": "0dbd4f72-4920-4b1a-cd41-e7c0d8979165"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported all packages and configured random seed to 1!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "cuda_available = torch.cuda.is_available()\n",
        "if cuda_available:\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    print('Using GPU.')\n",
        "else:\n",
        "    print('Using CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgl4rI5OEa7u",
        "outputId": "b5eea3fe-db9b-4b7c-dca6-a5401168c59f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Evaluator Class"
      ],
      "metadata": {
        "id": "F9Ktv8LP0qKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluator class that can be leveraged to measure the deployement cost of a DNN. The costs are usually quantified with the following metrics:\n",
        "1. Memory cost (in MB).\n",
        "2. FLOPs.\n",
        "3. MAC/MACCs (memory access cost/multiply-and-accumulate cost).\n",
        "\n",
        "For memory cost, notice that the unit used here is MB with $1024^2$B = 1MB. \n",
        "\n",
        "According to [2, 3], FLOPs can be quantified by multiplying the size of the feature map on the basis of the parameters. \n",
        "\n",
        "$$\\text{FLOPs} = \\left[\\left(K_h \\times K_w\\right) \\times c_1 +1\\right]  \\left( h \\times w \\right) c_2 \\\\\n",
        "= h w\\left[  K_h \\times K_w\\times c_1c_2 + c_2\\right] \\\\\n",
        "= \\text{feature map size} \\times  \\text{number of parameters}$$\n",
        "\n",
        "Notice that The input and output to convolutional layers are three-dimensional feature maps or namely tensors of size $h \\times w \\times c$ where $h$ and $w$ are spatial sizes of the feature map.\n",
        "\n",
        "For memory access cost (MAC), It can be quantified with number of multiply-and-accumulate operations (MACCs). [1] proposes a metric that sets a lower bound for MAC as \n",
        "\n",
        "\n",
        "$$\\text{MAC} \\geq 2 \\sqrt{h w B} + \\dfrac{B}{hw}$$\n",
        "\n",
        "It reaches the lower bound when input channels and output channels are equal.\n",
        "\n",
        "For $1\\times 1$ group convolution, MAC can be precisely calculated as\n",
        "\n",
        "$$\\text{MAC} = hw (c_1+c_2) + \\dfrac{c_1 c_2}{g} \\\\\n",
        "= hwc_1 + \\dfrac{Bg}{c_1} + \\dfrac{B}{hw}$$\n",
        "\n",
        "According to [2, 3], for a convolutional layer with kernel size $K$, MAC can be quantified with the number of MACCs as\n",
        "\n",
        "$$\\text{MAC} = \\left(K\\times K\\right) \\times \\left(h \\times w \\right)\\times c_1 \\times c_2 \\\\\n",
        "= \\text{kernel size} \\times \\text{feature map size} \\times \\text{input channel} \\times \\text{output channel}$$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1TiTjgC0W_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CostEvaluator:\n",
        "  def __init__(self, **kwargs):\n",
        "    # hyper-parameters\n",
        "    self.turn_on_log = kwargs.get(\"turn_on_log\", 0)\n",
        "\n",
        "  def memory_size_evaluator(self, nn_model):\n",
        "    param_size = 0\n",
        "    for param in nn_model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    buffer_size = 0\n",
        "    for buffer in nn_model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    total_size_mb = (param_size + buffer_size) / 1024**2\n",
        "    print('model size: {:.3f}MB'.format(total_size_mb))\n",
        "    return total_size_mb\n",
        "\n",
        "  def flops_evaluator(self, nn_model, in_channels, input_h, input_w):\n",
        "    # summing all layers together\n",
        "    total_flops = 0\n",
        "    h_prev = 0\n",
        "    w_prev = 0\n",
        "    h = input_h\n",
        "    w = input_w\n",
        "    c_prev = in_channels\n",
        "\n",
        "    counter = 0\n",
        "    # unwrap nn model\n",
        "    unwrapped_model = [module for module in nn_model.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "\n",
        "    for module in unwrapped_model:\n",
        "      if (self.turn_on_log):\n",
        "        print('processing layer {}'.format(counter))\n",
        "        print('layer type: {}'.format(type(module)))\n",
        "      # there is a possible change in output size if the module is a convolutional layer or maxpool layer\n",
        "      if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "        if (type(module.kernel_size) == int):\n",
        "          # handle int cases\n",
        "          if (module.kernel_size > 1 and module.stride > 1):\n",
        "            ratio = module.stride\n",
        "            h_prev = h\n",
        "            w_prev = w\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "        else:\n",
        "          # handle tuple cases\n",
        "          if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "            ratio = module.stride[0]\n",
        "            h_prev = h\n",
        "            w_prev = w\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "      elif (type(module) == torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
        "        h_prev = h\n",
        "        w_prev = w\n",
        "        h = 1\n",
        "        w = 1\n",
        "\n",
        "      if (type(module) == torch.nn.Conv2d):\n",
        "        # convolutional layer.\n",
        "        if (self.turn_on_log): print('calculating FLOPs for Conv2d...')\n",
        "        c_prev = module.out_channels\n",
        "        total_flops += ((module.kernel_size[0] * module.kernel_size[1]) * module.in_channels  + 1) * (h * w) * module.out_channels\n",
        "      elif (type(module) == torch.nn.MaxPool2d):\n",
        "        # handle else case with maxpool\n",
        "        if (self.turn_on_log): print('calculating FLOPs for MaxPool2d...')\n",
        "        # number of filters\n",
        "        n_1 = h_prev / module.stride\n",
        "        n_2 = w_prev / module.stride\n",
        "        n_tot = n_1 * n_2\n",
        "        # note that number of channels should be held unchanged\n",
        "        total_flops += (module.kernel_size * module.kernel_size + 1) * (h * w) * c_prev * n_tot\n",
        "      elif (type(module) == torch.nn.ReLU):\n",
        "        # handle else case with ReLU \n",
        "        # Assuming number of flops equal to length of input vector, ReLU takes 1 comparison and 1 multiplication\n",
        "        if (self.turn_on_log): print('calculating FLOPs for ReLU...')\n",
        "        total_flops += 2 * (h * w) * c_prev\n",
        "      elif (type(module) == torch.nn.BatchNorm2d):\n",
        "        # handle else case with BatchNorm\n",
        "        if (self.turn_on_log): print('calculating FLOPs for BatchNorm2d...')\n",
        "        mean_ops = (h * w) * module.num_features + 1\n",
        "        std_ops = 2 * ((h * w) * module.num_features + 1)\n",
        "        normalization_ops = 2 * (h * w) * module.num_features\n",
        "        scale_and_shift_ops = 2 * (h * w) * module.num_features\n",
        "        total_flops += mean_ops + std_ops + normalization_ops + scale_and_shift_ops\n",
        "\n",
        "      counter += 1\n",
        "      if (self.turn_on_log): print('------------------')\n",
        "\n",
        "    total_flops_G = total_flops / 10**9\n",
        "    print('total FLOPs: {:.3f} = {}G'.format(total_flops, total_flops_G))\n",
        "    return total_flops\n",
        "\n",
        "\n",
        "  def mac_evaluator(self, nn_model, input_h, input_w):\n",
        "    # summing all layers together\n",
        "    total_mac = 0\n",
        "    h = input_h\n",
        "    w = input_w\n",
        "\n",
        "    # unwrap the nn model\n",
        "    # the complete ResNet object is specifically excluded\n",
        "    unwrapped_model = [module for module in nn_model.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "\n",
        "    counter = 0\n",
        "    for module in unwrapped_model:\n",
        "      if (self.turn_on_log): print('processing layer {}'.format(counter))\n",
        "      if (self.turn_on_log): print('layer type: {}'.format(type(module)))\n",
        "      if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "        if (type(module.kernel_size) == int):\n",
        "          # handle int case\n",
        "          if (module.kernel_size > 1 and module.stride > 1):\n",
        "            ratio = module.stride\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "        else:\n",
        "          # handle tuple case\n",
        "          if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "            ratio = module.stride[0]\n",
        "            h = h / ratio\n",
        "            w = w / ratio\n",
        "            if (self.turn_on_log): print('output dimensions shrinking')\n",
        "      elif (type(module) == torch.nn.modules.pooling.AdaptiveAvgPool2d):\n",
        "        h_prev = h\n",
        "        w_prev = w\n",
        "        h = 1\n",
        "        w = 1\n",
        "\n",
        "      if (type(module) == torch.nn.Conv2d):\n",
        "        # MAC operations are dominated by computations carried out in convolutional layer\n",
        "        total_mac += (module.in_channels * module.out_channels) * (h * w) * (module.kernel_size[0] * module.kernel_size[1])\n",
        "      counter += 1\n",
        "      if (self.turn_on_log): print('------------------')\n",
        "    total_mac_G = total_mac / 10**9\n",
        "    print('total MACCs: {:.3f} = {}G'.format(total_mac, total_mac_G))\n",
        "    return total_mac\n",
        "  \n",
        "  def inference_time_evaluator(self, device_flops, device_name, nn_model, in_channels, input_h, input_w):\n",
        "    print('starting inference time analysis...')\n",
        "    total_flop = self.flops_evaluator(nn_model, in_channels, input_h, input_w)\n",
        "    inf_time = total_flop / device_flops\n",
        "    print('total inference time: {:.3f}s with {}'.format(inf_time, device_name))\n",
        "    return total_flop / device_flops\n",
        "\n",
        "  def power_evaluator(self, device_power_spec, device_flops, nn_model, in_channels, input_h, input_w):\n",
        "    print('starting inference power analysis...')\n",
        "    total_flop = self.flops_evaluator(nn_model, in_channels, input_h, input_w)\n",
        "    inf_time = total_flop / device_flops\n",
        "    power = inf_time * device_power_spec\n",
        "    print('total inference power consumption: {:.3f}s'.format(power))\n",
        "    return power"
      ],
      "metadata": {
        "id": "HUslWiply1nl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50 Deployment Cost Estimation"
      ],
      "metadata": {
        "id": "7kfe__74jDfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)"
      ],
      "metadata": {
        "id": "4lCoycqcblHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "e28a0651bdc14d3788dc17b853ae83ac",
            "11df1b3d196b4e81a950ce983e2007d5",
            "9221fa851e664b4d8315ddb7a35fa73a",
            "b5afd225146b469eb721eaafa6b70c2a",
            "de0cc2be3b2b468fbfd75d35f017ccf1",
            "e192f4bb98904b89810e40f78785119d",
            "ee274a55fef34b27a2b8df48edb07c03",
            "a5d1797ae37c499c87f721c968887e65",
            "e643ecf682854e2c8426433d0d322443",
            "49cdfa262b1a451e8ba8d8cf9c1fe84f",
            "88f8e54f5f694773a58926658a2b87ee"
          ]
        },
        "outputId": "37c529e9-cbcd-40dd-9c55-874afb08f200"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28a0651bdc14d3788dc17b853ae83ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider standard imagenet input\n",
        "summary(resnet_50, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaFDOK98ke_G",
        "outputId": "c865fa1d-18ea-444d-d66b-70929bd3620f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.56\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 384.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_resnet50 = [module for module in resnet_50.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "param_size = 0\n",
        "counter = 0\n",
        "\n",
        "for module in unwrapped_resnet50:\n",
        "  print(type(module))\n",
        "  counter += 1\n",
        "print(counter)\n",
        "\n",
        "counter = 0\n",
        "for param in resnet_50.parameters():\n",
        "  counter += 1\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "Y-2hpe_Cb5e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404c9135-5b97-4f2e-8618-eb5c36b67ad0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torchvision.models.resnet.Bottleneck'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.conv.Conv2d'>\n",
            "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
            "<class 'torch.nn.modules.activation.ReLU'>\n",
            "<class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>\n",
            "<class 'torch.nn.modules.linear.Linear'>\n",
            "142\n",
            "161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_resnet50 = [module for module in resnet_50.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "for module in unwrapped_resnet50:\n",
        "  if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "    print(module.kernel_size)\n",
        "    if (type(module.kernel_size) == int):\n",
        "      # handle int case\n",
        "      if (module.kernel_size > 1 and module.stride > 1):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    else:\n",
        "      # handle tuple case\n",
        "      if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxTovHP64N74",
        "outputId": "0286e140-60b0-46c7-ddb6-e7ebfa161266"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 7)\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "2\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "r88TDRCjwR_t"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_mem = evaluator.memory_size_evaluator(resnet_50)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "resnet50_flops = evaluator.flops_evaluator(resnet_50, 3, 224, 224)\n",
        "resnet50_mac = evaluator.mac_evaluator(resnet_50, 224, 224)\n",
        "resnet50_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', resnet_50, 3, 224, 224)\n",
        "resnet50_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', resnet_50, 3, 224, 224)\n",
        "resnet50_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', resnet_50, 3, 224, 224)\n",
        "resnet50_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', resnet_50, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1F5nM_M_O4p",
        "outputId": "4b46697d-2506-4d7f-d0bf-aa5b670d3775"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 97.695MB\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total MACCs: 4087136256.000 = 4.087136256G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.218s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.008s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.001s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 10482770079.000 = 10.482770079G\n",
            "total inference time: 0.001s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamically Gated ResNet_50 (SkipNet) Cost Estimation"
      ],
      "metadata": {
        "id": "c3e5tv2q9uyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ucbdrive/skipnet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDALKNKH961h",
        "outputId": "92578c3e-a5ca-47c2-f498-63ffb5eaac65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'skipnet'...\n",
            "remote: Enumerating objects: 261, done.\u001b[K\n",
            "remote: Total 261 (delta 0), reused 0 (delta 0), pack-reused 261\u001b[K\n",
            "Receiving objects: 100% (261/261), 1.69 MiB | 9.86 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl 'http://people.eecs.berkeley.edu/~xinw/skipnet/resnet-50-rnn-sp-imagenet.pth.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS9wkpReBh_L",
        "outputId": "7c434a37-95ce-4dc9-d920-cbde7d8ea90e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Binary output can mess up your terminal. Use \"--output -\" to tell \n",
            "Warning: curl to output it to your terminal anyway, or consider \"--output \n",
            "Warning: <FILE>\" to save to a file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"http://people.eecs.berkeley.edu/~xinw/skipnet/resnet-50-rnn-sp-imagenet.pth.tar\" \\\n",
        "  -o resnet-50-rnn-sp-imagenet.pth.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxQa1LD5KAqx",
        "outputId": "5b6f433c-eced-4762-f1a1-837f1607d0f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 98.3M  100 98.3M    0     0  71.5M      0  0:00:01  0:00:01 --:--:-- 71.5M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skipnet.imagenet import models"
      ],
      "metadata": {
        "id": "nfL5E6KRG4hT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pkgutil import iter_modules\n",
        "\n",
        "def list_submodules(module):\n",
        "    for submodule in iter_modules(module.__path__):\n",
        "        print(submodule.name)\n",
        "\n",
        "list_submodules(skipnet.imagenet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MItyQD4kLQLN",
        "outputId": "2bd7e960-9356-437d-9021-de645c3f15b0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models\n",
            "train_base\n",
            "train_rl\n",
            "train_sp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_gate_50 = models.imagenet_rnn_gate_50(pretrained=True)"
      ],
      "metadata": {
        "id": "I7HwsNyKL8CD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_rnn_gate_50 = [module for module in rnn_gate_50.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "for module in unwrapped_rnn_gate_50:\n",
        "  if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "    print(module.kernel_size)\n",
        "    if (type(module.kernel_size) == int):\n",
        "      # handle int case\n",
        "      if (module.kernel_size > 1 and module.stride > 1):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    else:\n",
        "      # handle tuple case\n",
        "      if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUgBOGvKFl3C",
        "outputId": "f27ed61c-2e1c-441c-9d16-c8b5533f9626"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 7)\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "2\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "9FfqHta6Qe-9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_gate_50_mem = evaluator.memory_size_evaluator(rnn_gate_50)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "rnn_gate_50_flops = evaluator.flops_evaluator(rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_mac = evaluator.mac_evaluator(rnn_gate_50, 224, 224)\n",
        "rnn_gate_50_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', rnn_gate_50, 3, 224, 224)\n",
        "rnn_gate_50_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', rnn_gate_50, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RniFEarFsvx",
        "outputId": "bc92222e-a3ac-45c3-d52d-708b6811b05e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 98.276MB\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total MACCs: 5067174378.000 = 5.067174378G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.239s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.009s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.001s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 11479806056.000 = 11.479806056G\n",
            "total inference time: 0.001s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OFA Cost Estimation (MobileNetV3 as the backbone NN)"
      ],
      "metadata": {
        "id": "ErQ7P6c6SbfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Model"
      ],
      "metadata": {
        "id": "vonVn1_0aJya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Installing thop (FLOPs counter) ...')\n",
        "! pip install thop 1>/dev/null\n",
        "# ofa is a package containing training code, pretrained specialized models and inference code for the once-for-all networks.\n",
        "print('Installing OFA...')\n",
        "! pip install ofa 1>/dev/null\n",
        "# tqdm is a package for displaying a progress bar.\n",
        "print('Installing tqdm (progress bar) ...')\n",
        "! pip install tqdm 1>/dev/null\n",
        "print('Installing matplotlib...')\n",
        "! pip install matplotlib 1>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_y6F4cVSu1",
        "outputId": "bea89624-5f69-4a74-d0f5-6d191ddb11e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing thop (FLOPs counter) ...\n",
            "Installing OFA...\n",
            "Installing tqdm (progress bar) ...\n",
            "Installing matplotlib...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.utils import download_url"
      ],
      "metadata": {
        "id": "z-epRADOXqXp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ofa.tutorial import AccuracyPredictor, FLOPsTable, LatencyTable, EvolutionFinder\n",
        "from ofa.tutorial import evaluate_ofa_subnet, evaluate_ofa_specialized"
      ],
      "metadata": {
        "id": "VRqIi3R-X4U1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ofa_network = ofa_net('ofa_mbv3_d234_e346_k357_w1.2', pretrained=True)\n",
        "print('The OFA Network is ready.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dylqnYS2YUVZ",
        "outputId": "ae44d4e9-b189-4897-be0e-3db6dd5b5d2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/ofa_nets/ofa_mbv3_d234_e346_k357_w1.2\" to .torch/ofa_nets/ofa_mbv3_d234_e346_k357_w1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The OFA Network is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unwrapped_ofa_network = [module for module in ofa_network.modules() if not isinstance(module, torch.nn.modules.container.Sequential) and not isinstance(module, torchvision.models.resnet.ResNet)]\n",
        "for module in unwrapped_ofa_network:\n",
        "  if (type(module) == torch.nn.modules.conv.Conv2d or type(module) == torch.nn.modules.pooling.MaxPool2d):\n",
        "    print(module.kernel_size)\n",
        "    if (type(module.kernel_size) == int):\n",
        "      # handle int case\n",
        "      if (module.kernel_size > 1 and module.stride > 1):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    else:\n",
        "      # handle tuple case\n",
        "      if ((module.kernel_size[0] > 1 or module.kernel_size[1] > 1) and (module.stride[0] > 1 or module.stride[1] > 1)):\n",
        "        print(module)\n",
        "        print(module.stride)\n",
        "        print('size shrinking')\n",
        "    print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcLEaC4YfJX",
        "outputId": "433cd36c-8106-4c08-f2ec-843031cd164d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n",
            "Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(3, 3)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), groups=144, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(192, 192, kernel_size=(7, 7), stride=(2, 2), groups=192, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(288, 288, kernel_size=(7, 7), stride=(2, 2), groups=288, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "Conv2d(816, 816, kernel_size=(7, 7), stride=(2, 2), groups=816, bias=False)\n",
            "(2, 2)\n",
            "size shrinking\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(7, 7)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n",
            "(1, 1)\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "VNxan7sDZ4wl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ofa_network_mem = evaluator.memory_size_evaluator(ofa_network)\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "ofa_network_flops = evaluator.flops_evaluator(ofa_network, 3, 224, 224)\n",
        "ofa_network_mac = evaluator.mac_evaluator(ofa_network, 224, 224)\n",
        "ofa_network_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', ofa_network, 3, 224, 224)\n",
        "ofa_network_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', ofa_network, 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGe0PlweYven",
        "outputId": "e061d362-c08c-4fcd-c755-47c7b03ffabf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 41.072MB\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total MACCs: 76273854720.000 = 76.27385472G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 1.592s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.057s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.006s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 76392489792.000 = 76.392489792G\n",
            "total inference time: 0.008s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subnet for SamSung Note10"
      ],
      "metadata": {
        "id": "zufkCVfDaNCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageNet Dataset:"
      ],
      "metadata": {
        "id": "UL6JdG9Ga9ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cuda_available:\n",
        "    # path to the ImageNet dataset\n",
        "    print(\"Please input the path to the ImageNet dataset.\\n\")\n",
        "    imagenet_data_path = input()\n",
        "\n",
        "    # if 'imagenet_data_path' is empty, download a subset of ImageNet containing 2000 images (~250M) for test\n",
        "    if not os.path.isdir(imagenet_data_path):\n",
        "        os.makedirs(imagenet_data_path, exist_ok=True)\n",
        "        download_url('https://hanlab.mit.edu/files/OnceForAll/ofa_cvpr_tutorial/imagenet_1k.zip', model_dir='data')\n",
        "        ! cd data && unzip imagenet_1k 1>/dev/null && cd ..\n",
        "        ! cp -r data/imagenet_1k/* $imagenet_data_path\n",
        "        ! rm -rf data\n",
        "        print('%s is empty. Download a subset of ImageNet for test.' % imagenet_data_path)\n",
        "\n",
        "    print('The ImageNet dataset files are ready.')\n",
        "else:\n",
        "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l72wgBboazxu",
        "outputId": "941e889d-a80e-4843-b788-335c21eaa7e5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please input the path to the ImageNet dataset.\n",
            "\n",
            "/home/dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/ofa_cvpr_tutorial/imagenet_1k.zip\" to data/imagenet_1k.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/dataset is empty. Download a subset of ImageNet for test.\n",
            "The ImageNet dataset files are ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader:"
      ],
      "metadata": {
        "id": "Nx63u4KHbBCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cuda_available:\n",
        "    # The following function build the data transforms for test\n",
        "    def build_val_transform(size):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(int(math.ceil(size / 0.875))),\n",
        "            transforms.CenterCrop(size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(\n",
        "            root=os.path.join(imagenet_data_path, 'val'),\n",
        "            transform=build_val_transform(224)\n",
        "        ),\n",
        "        batch_size=250,  # test batch size\n",
        "        shuffle=True,\n",
        "        num_workers=16,  # number of workers for the data loader\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "    )\n",
        "    print('The ImageNet dataloader is ready.')\n",
        "else:\n",
        "    data_loader = None\n",
        "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNqCyjsua5L8",
        "outputId": "4bc2a9c1-5612-4b06-f291-d29dc8f8e10e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ImageNet dataloader is ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy predictor\n",
        "accuracy_predictor = AccuracyPredictor(\n",
        "    pretrained=True,\n",
        "    device='cuda:0' if cuda_available else 'cpu'\n",
        ")\n",
        "\n",
        "print('The accuracy predictor is ready!')\n",
        "print(accuracy_predictor.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stb8DHnDaizS",
        "outputId": "b8dba202-66e7-4e5c-a70a-b36688ffb3ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/acc_predictor.pth\" to /root/.torch/acc_predictor.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy predictor is ready!\n",
            "Sequential(\n",
            "  (0): Linear(in_features=128, out_features=400, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=400, out_features=400, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=400, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_hardware = 'note10'\n",
        "latency_table = LatencyTable(device=target_hardware)\n",
        "print('The Latency lookup table on %s is ready!' % target_hardware)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrA6mrgraDUD",
        "outputId": "eea0d486-a955-4c1d-a3ab-6047522adc83"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/160_lookup_table.yaml\" to /root/.hancai/latency_tools/160_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 160.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/176_lookup_table.yaml\" to /root/.hancai/latency_tools/176_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/192_lookup_table.yaml\" to /root/.hancai/latency_tools/192_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 192.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/208_lookup_table.yaml\" to /root/.hancai/latency_tools/208_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 208.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/tutorial/latency_table@note10/224_lookup_table.yaml\" to /root/.hancai/latency_tools/224_lookup_table.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built latency table for image size: 224.\n",
            "The Latency lookup table on note10 is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Hyper-parameters for the evolutionary search process\n",
        "    You can modify these hyper-parameters to see how they influence the final ImageNet accuracy of the search sub-net.\n",
        "\"\"\"\n",
        "latency_constraint = 25  # ms, suggested range [15, 33] ms\n",
        "P = 100  # The size of population in each generation\n",
        "N = 500  # How many generations of population to be searched\n",
        "r = 0.25  # The ratio of networks that are used as parents for next generation\n",
        "params = {\n",
        "    'constraint_type': target_hardware, # Let's do latency-constrained search\n",
        "    'efficiency_constraint': latency_constraint,\n",
        "    'mutate_prob': 0.1, # The probability of mutation in evolutionary search\n",
        "    'mutation_ratio': 0.5, # The ratio of networks that are generated through mutation in generation n >= 2.\n",
        "    'efficiency_predictor': latency_table, # To use a predefined efficiency predictor.\n",
        "    'accuracy_predictor': accuracy_predictor, # To use a predefined accuracy_predictor predictor.\n",
        "    'population_size': P,\n",
        "    'max_time_budget': N,\n",
        "    'parent_ratio': r,\n",
        "}\n",
        "\n",
        "# build the evolution finder\n",
        "finder = EvolutionFinder(**params)\n",
        "\n",
        "# start searching\n",
        "result_lis = []\n",
        "st = time.time()\n",
        "best_valids, best_info = finder.run_evolution_search()\n",
        "result_lis.append(best_info)\n",
        "ed = time.time()\n",
        "print('Found best architecture on %s with latency <= %.2f ms in %.2f seconds! '\n",
        "      'It achieves %.2f%s predicted accuracy with %.2f ms latency on %s.' %\n",
        "      (target_hardware, latency_constraint, ed-st, best_info[0] * 100, '%', best_info[-1], target_hardware))\n",
        "\n",
        "# visualize the architecture of the searched sub-net\n",
        "_, net_config, latency = best_info\n",
        "ofa_network.set_active_subnet(ks=net_config['ks'], d=net_config['d'], e=net_config['e'])\n",
        "print('Architecture of the searched sub-net:')\n",
        "print(ofa_network.module_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP68svPkacXB",
        "outputId": "563ab15b-b872-4320-e471-cd2b438d6246"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Searching with note10 constraint (25): 100%|██████████| 500/500 [00:19<00:00, 25.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found best architecture on note10 with latency <= 25.00 ms in 19.70 seconds! It achieves 81.44% predicted accuracy with 24.89 ms latency on note10.\n",
            "Architecture of the searched sub-net:\n",
            "3x3_Conv_O24_H_SWISH_BN\n",
            "(3x3_MBConv1_RELU_O24_BN, Identity)\n",
            "((O32, E3.0, K5), None)\n",
            "((O32, E4.0, K3), Identity)\n",
            "(SE(O48, E4.0, K7), None)\n",
            "(SE(O48, E4.0, K5), Identity)\n",
            "((O96, E4.0, K7), None)\n",
            "((O96, E3.0, K7), Identity)\n",
            "((O96, E4.0, K3), Identity)\n",
            "(SE(O136, E6.0, K3), None)\n",
            "(SE(O136, E3.0, K5), Identity)\n",
            "(SE(O136, E3.0, K5), Identity)\n",
            "(SE(O136, E3.0, K3), Identity)\n",
            "(SE(O192, E6.0, K7), None)\n",
            "(SE(O192, E6.0, K3), Identity)\n",
            "(SE(O192, E4.0, K3), Identity)\n",
            "(SE(O192, E3.0, K5), Identity)\n",
            "1x1_Conv_O1152_H_SWISH_BN\n",
            "1x1_Conv_O1536_H_SWISH\n",
            "1536x1000_Linear\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the searched model on ImageNet\n",
        "if cuda_available:\n",
        "    top1s = []\n",
        "    latency_list = []\n",
        "    for result in result_lis:\n",
        "        _, net_config, latency = result\n",
        "        print('Evaluating the sub-network with latency = %.1f ms on %s' % (latency, target_hardware))\n",
        "        top1 = evaluate_ofa_subnet(\n",
        "            ofa_network,\n",
        "            imagenet_data_path,\n",
        "            net_config,\n",
        "            data_loader,\n",
        "            batch_size=250,\n",
        "            device='cuda:0' if cuda_available else 'cpu')\n",
        "        top1s.append(top1)\n",
        "        latency_list.append(latency)\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.plot(latency_list, top1s, 'x-', marker='*', color='darkred',  linewidth=2, markersize=8, label='OFA')\n",
        "    plt.plot([26, 45], [74.6, 76.7], '--', marker='+', linewidth=2, markersize=8, label='ProxylessNAS')\n",
        "    plt.plot([15.3, 22, 31], [73.3, 75.2, 76.6], '--', marker='>', linewidth=2, markersize=8, label='MobileNetV3')\n",
        "    plt.xlabel('%s Latency (ms)' % target_hardware, size=12)\n",
        "    plt.ylabel('ImageNet Top-1 Accuracy (%)', size=12)\n",
        "    plt.legend(['OFA', 'ProxylessNAS', 'MobileNetV3'], loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('Successfully draw the tradeoff curve!')\n",
        "else:\n",
        "    print('Since GPU is not found in the environment, we skip all scripts related to ImageNet evaluation.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "FNh_ehV1aguw",
        "outputId": "34e939ee-3811-41c0-f1f8-9e0355a4bf0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the sub-network with latency = 24.9 ms on note10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Validate: 100%|██████████| 4/4 [00:07<00:00,  1.97s/it, loss=0.926, top1=78.2, top5=94.8, img_size=192]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: loss=0.92586,\t top1=78.2,\t top5=94.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully draw the tradeoff curve!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = CostEvaluator();"
      ],
      "metadata": {
        "id": "-_vgDc98bTCK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider only the OFA subnet:"
      ],
      "metadata": {
        "id": "x8m0PSfz0P4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ofa_network_mem = evaluator.memory_size_evaluator(ofa_network.get_active_subnet())\n",
        "# consider running resnet50 on Cortex A76 with 3GHz and 16FLOPs for single-point precision\n",
        "a76_flops = 16 * 3 * 10**9\n",
        "jetson_nx_flops = 1.33 * 10**(12) # 1.33 TFLOPs\n",
        "rtx_2080_flops = 13.45 * 10**(12) # 13.45 TFLOPs\n",
        "gtx_1080_flops = 9 * 10**(12) # 9 TFLOPs\n",
        "ofa_network_flops = evaluator.flops_evaluator(ofa_network.get_active_subnet(), 3, 224, 224)\n",
        "ofa_network_mac = evaluator.mac_evaluator(ofa_network.get_active_subnet(), 224, 224)\n",
        "ofa_network_inference_a76 = evaluator.inference_time_evaluator(a76_flops, 'Cortex A76', ofa_network.get_active_subnet(), 3, 224, 224)\n",
        "ofa_network_inference_nx = evaluator.inference_time_evaluator(jetson_nx_flops, 'Jetson Xavier NX', ofa_network.get_active_subnet(), 3, 224, 224)\n",
        "ofa_network_inference_rtx2080 = evaluator.inference_time_evaluator(rtx_2080_flops, 'RTX 2080 GPU', ofa_network.get_active_subnet(), 3, 224, 224)\n",
        "ofa_network_inference_gtx1080 = evaluator.inference_time_evaluator(gtx_1080_flops, 'GTX 1080 GPU', ofa_network.get_active_subnet(), 3, 224, 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPAoZ7bibKUp",
        "outputId": "678790e3-028a-488c-879b-1a530caa6df9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 28.774MB\n",
            "total FLOPs: 9689571395.000 = 9.689571395G\n",
            "total MACCs: 9635899392.000 = 9.635899392G\n",
            "starting inference time analysis...\n",
            "total FLOPs: 9689571395.000 = 9.689571395G\n",
            "total inference time: 0.202s with Cortex A76\n",
            "starting inference time analysis...\n",
            "total FLOPs: 9689571395.000 = 9.689571395G\n",
            "total inference time: 0.007s with Jetson Xavier NX\n",
            "starting inference time analysis...\n",
            "total FLOPs: 9689571395.000 = 9.689571395G\n",
            "total inference time: 0.001s with RTX 2080 GPU\n",
            "starting inference time analysis...\n",
            "total FLOPs: 9689571395.000 = 9.689571395G\n",
            "total inference time: 0.001s with GTX 1080 GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Us0ZZzvJbTs_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}